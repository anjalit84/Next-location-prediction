{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HMM Training on 10 Users' Trajectories\n",
        "\n",
        "This notebook:\n",
        "- Loads 10 users' trajectories\n",
        "- Removes consecutive duplicates (AAABCDCCABB → ABCDCAB) for each user\n",
        "- Creates sequences of length 50 from all users\n",
        "- Trains HMM model on combined data\n",
        "- Evaluates all 4 metrics: Accuracy, Precision & Recall, Top-K Accuracy, MPD\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1 — Imports & Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "from haversine import haversine\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from hmmlearn import hmm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds\n",
        "np.random.seed(42)\n",
        "\n",
        "# Paths\n",
        "BASE_PATH = \"/home/root495/Inexture/Location Prediction Update\"\n",
        "PROCESSED_PATH = BASE_PATH + \"/data/processed/\"\n",
        "SEQUENCES_FILE = PROCESSED_PATH + \"place_sequences.json\"\n",
        "GRID_METADATA_FILE = PROCESSED_PATH + \"grid_metadata.json\"\n",
        "CLEANED_WITH_PLACES_FILE = PROCESSED_PATH + \"cleaned_with_places.csv\"\n",
        "OUTPUT_PATH = BASE_PATH + \"/notebooks/\"\n",
        "MODELS_PATH = BASE_PATH + \"/models/\"\n",
        "RESULTS_PATH = BASE_PATH + \"/results/\"\n",
        "MODEL_SAVE_PATH = MODELS_PATH + \"hmm_10users_model.pkl\"\n",
        "RESULTS_SAVE_PATH = RESULTS_PATH + \"hmm_10users_results.json\"\n",
        "\n",
        "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "os.makedirs(MODELS_PATH, exist_ok=True)\n",
        "os.makedirs(RESULTS_PATH, exist_ok=True)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 2 — Load 10 Users' Trajectories\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading place sequences...\n",
            "Total users available: 54\n",
            "\n",
            "Selected 10 users: ['000', '001', '005', '006', '009', '011', '014', '016', '019', '025']\n",
            "  User 000: 173817 places\n",
            "  User 001: 108561 places\n",
            "  User 005: 108967 places\n",
            "  User 006: 31809 places\n",
            "  User 009: 84573 places\n",
            "  User 011: 90770 places\n",
            "  User 014: 388051 places\n",
            "  User 016: 89208 places\n",
            "  User 019: 47792 places\n",
            "  User 025: 628816 places\n",
            "\n",
            "Total places across all 10 users: 1752364\n"
          ]
        }
      ],
      "source": [
        "# Load place sequences\n",
        "print(\"Loading place sequences...\")\n",
        "with open(SEQUENCES_FILE, 'r') as f:\n",
        "    sequences_dict = json.load(f)\n",
        "\n",
        "print(f\"Total users available: {len(sequences_dict)}\")\n",
        "\n",
        "# Select first 10 users\n",
        "user_ids = list(sequences_dict.keys())\n",
        "NUM_USERS = 10\n",
        "selected_users = user_ids[:NUM_USERS]\n",
        "\n",
        "print(f\"\\nSelected {NUM_USERS} users: {selected_users}\")\n",
        "\n",
        "# Load sequences for all selected users\n",
        "user_sequences = {}\n",
        "total_places = 0\n",
        "for user_id in selected_users:\n",
        "    seq = sequences_dict[user_id]\n",
        "    user_sequences[user_id] = seq\n",
        "    total_places += len(seq)\n",
        "    print(f\"  User {user_id}: {len(seq)} places\")\n",
        "\n",
        "print(f\"\\nTotal places across all {NUM_USERS} users: {total_places}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 3 — Preprocess: Remove Consecutive Duplicates\n",
        "\n",
        "Remove consecutive duplicate locations for each user. Example: AAABCDCCABB → ABCDCAB\n",
        "\n",
        "Only consecutive duplicates are removed. If a location appears again later (non-consecutive), it is kept.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing users...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Removing duplicates:  50%|█████     | 5/10 [00:00<00:00, 44.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  User 000: 173817 → 795 places (99.5% reduction)\n",
            "  User 001: 108561 → 186 places (99.8% reduction)\n",
            "  User 005: 108967 → 283 places (99.7% reduction)\n",
            "  User 006: 31809 → 103 places (99.7% reduction)\n",
            "  User 009: 84573 → 17 places (100.0% reduction)\n",
            "  User 011: 90770 → 125 places (99.9% reduction)\n",
            "  User 014: 388051 → 766 places (99.8% reduction)\n",
            "  User 016: 89208 → 124 places (99.9% reduction)\n",
            "  User 019: 47792 → 120 places (99.7% reduction)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Removing duplicates: 100%|██████████| 10/10 [00:00<00:00, 36.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  User 025: 628816 → 1568 places (99.8% reduction)\n",
            "\n",
            "Summary:\n",
            "  Total original places: 1752364\n",
            "  Total after processing: 4087\n",
            "  Total duplicates removed: 1748277 (99.8%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def remove_consecutive_duplicates(sequence):\n",
        "    \"\"\"\n",
        "    Remove consecutive duplicates from sequence.\n",
        "    Example: [A, A, A, B, C, D, C, C, A, B, B] → [A, B, C, D, C, A, B]\n",
        "    \"\"\"\n",
        "    if len(sequence) == 0:\n",
        "        return sequence\n",
        "    \n",
        "    processed = [sequence[0]]  # Always keep first element\n",
        "    \n",
        "    for i in range(1, len(sequence)):\n",
        "        # Only add if different from previous (not consecutive duplicate)\n",
        "        if sequence[i] != sequence[i-1]:\n",
        "            processed.append(sequence[i])\n",
        "    \n",
        "    return processed\n",
        "\n",
        "# Apply consecutive duplicate removal to each user\n",
        "processed_sequences = {}\n",
        "total_original = 0\n",
        "total_processed = 0\n",
        "\n",
        "print(\"Processing users...\")\n",
        "for user_id in tqdm(selected_users, desc=\"Removing duplicates\"):\n",
        "    original_seq = user_sequences[user_id]\n",
        "    processed_seq = remove_consecutive_duplicates(original_seq)\n",
        "    processed_sequences[user_id] = processed_seq\n",
        "    \n",
        "    original_len = len(original_seq)\n",
        "    processed_len = len(processed_seq)\n",
        "    total_original += original_len\n",
        "    total_processed += processed_len\n",
        "    \n",
        "    reduction = original_len - processed_len\n",
        "    reduction_pct = (reduction / original_len * 100) if original_len > 0 else 0\n",
        "    print(f\"  User {user_id}: {original_len} → {processed_len} places ({reduction_pct:.1f}% reduction)\")\n",
        "\n",
        "print(f\"\\nSummary:\")\n",
        "print(f\"  Total original places: {total_original}\")\n",
        "print(f\"  Total after processing: {total_processed}\")\n",
        "print(f\"  Total duplicates removed: {total_original - total_processed} ({((total_original - total_processed)/total_original*100):.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 4 — Create Sequences of Length 50\n",
        "\n",
        "Split each user's processed sequence into fixed-length chunks of 50 events each.\n",
        "Combine sequences from all users for training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating sequences from all users...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing users: 100%|██████████| 10/10 [00:00<00:00, 22298.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  User 000: 30 sequences\n",
            "  User 001: 6 sequences\n",
            "  User 005: 10 sequences\n",
            "  User 006: 3 sequences\n",
            "  User 009: 0 sequences\n",
            "  User 011: 4 sequences\n",
            "  User 014: 29 sequences\n",
            "  User 016: 3 sequences\n",
            "  User 019: 3 sequences\n",
            "  User 025: 61 sequences\n",
            "\n",
            "Total sequences created: 149\n",
            "Total events in sequences: 7450\n",
            "\n",
            "Training sequences: 119\n",
            "Test sequences: 30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Create sequences of fixed length 50\n",
        "SEQUENCE_LENGTH = 50\n",
        "\n",
        "# Use sliding windows for more training data (overlap helps with learning)\n",
        "# Create overlapping sequences with step size of 25 (50% overlap)\n",
        "all_sequences = []\n",
        "step_size = 25  # Overlap of 50%\n",
        "\n",
        "print(\"Creating sequences from all users...\")\n",
        "for user_id in tqdm(selected_users, desc=\"Processing users\"):\n",
        "    processed_seq = processed_sequences[user_id]\n",
        "    user_sequences_list = []\n",
        "    \n",
        "    for i in range(0, len(processed_seq) - SEQUENCE_LENGTH + 1, step_size):\n",
        "        chunk = processed_seq[i:i+SEQUENCE_LENGTH]\n",
        "        if len(chunk) == SEQUENCE_LENGTH:  # Only full-length sequences\n",
        "            user_sequences_list.append(chunk)\n",
        "    \n",
        "    all_sequences.extend(user_sequences_list)\n",
        "    print(f\"  User {user_id}: {len(user_sequences_list)} sequences\")\n",
        "\n",
        "print(f\"\\nTotal sequences created: {len(all_sequences)}\")\n",
        "print(f\"Total events in sequences: {sum(len(s) for s in all_sequences)}\")\n",
        "\n",
        "# Split into train/test (80/20)\n",
        "split_idx = int(len(all_sequences) * 0.8)\n",
        "train_sequences = all_sequences[:split_idx]\n",
        "test_sequences = all_sequences[split_idx:]\n",
        "\n",
        "print(f\"\\nTraining sequences: {len(train_sequences)}\")\n",
        "print(f\"Test sequences: {len(test_sequences)}\")\n",
        "\n",
        "if len(test_sequences) == 0:\n",
        "    # If no test sequences, use last training sequence for testing\n",
        "    test_sequences = [train_sequences[-1]]\n",
        "    train_sequences = train_sequences[:-1]\n",
        "    print(f\"Adjusted: Training={len(train_sequences)}, Test=1 (using last training sequence)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 5 — Encode Sequences\n",
        "\n",
        "Encode place_ids to integers for HMM training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding sequences...\n",
            "Unique places across all users: 303\n",
            "Encoded 119 training sequences\n",
            "Encoded 30 test sequences\n",
            "Created mapping for 303 place IDs\n"
          ]
        }
      ],
      "source": [
        "# Encode sequences to integers\n",
        "print(\"Encoding sequences...\")\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Flatten all sequences for encoding\n",
        "all_places = [place for seq in train_sequences + test_sequences for place in seq]\n",
        "le.fit(all_places)\n",
        "\n",
        "print(f\"Unique places across all users: {len(le.classes_)}\")\n",
        "\n",
        "# Encode training sequences\n",
        "train_encoded = []\n",
        "for seq in train_sequences:\n",
        "    encoded = le.transform(seq).tolist()\n",
        "    train_encoded.append(encoded)\n",
        "\n",
        "# Encode test sequences\n",
        "test_encoded = []\n",
        "for seq in test_sequences:\n",
        "    encoded = le.transform(seq).tolist()\n",
        "    test_encoded.append(encoded)\n",
        "\n",
        "print(f\"Encoded {len(train_encoded)} training sequences\")\n",
        "print(f\"Encoded {len(test_encoded)} test sequences\")\n",
        "\n",
        "# Create mapping from encoded ID to original place_id for coordinate lookup\n",
        "encoded_to_placeid = {}\n",
        "for place_id in le.classes_:\n",
        "    encoded_id = le.transform([place_id])[0]\n",
        "    encoded_to_placeid[int(encoded_id)] = place_id\n",
        "\n",
        "print(f\"Created mapping for {len(encoded_to_placeid)} place IDs\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 6 — Train HMM\n",
        "\n",
        "Train Hidden Markov Model on the encoded sequences from all 10 users.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fitting a model with 17599 free scalar parameters with only 5950 data points will result in a degenerate solution.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data prepared:\n",
            "  X shape: (5950, 1)\n",
            "  Number of sequences: 119\n",
            "  Total observations: 5950\n",
            "  Average sequence length: 50.0\n",
            "\n",
            "Unique encoded states: 303\n",
            "Using 50 hidden states for HMM\n",
            "\n",
            "Training HMM model...\n",
            "Note: Using CategoricalHMM (correct for categorical observations)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "         1  -33852.76221280             +nan\n",
            "         2  -17052.28737068  +16800.47484211\n",
            "         3  -13562.14904398   +3490.13832670\n",
            "         4  -11569.00173274   +1993.14731124\n",
            "         5  -10978.66570326    +590.33602948\n",
            "         6  -10704.88698069    +273.77872257\n",
            "         7  -10579.44322503    +125.44375566\n",
            "         8  -10492.76697490     +86.67625012\n",
            "         9  -10424.32197418     +68.44500072\n",
            "        10  -10368.21611924     +56.10585494\n",
            "        11  -10324.89692545     +43.31919379\n",
            "        12  -10299.06892932     +25.82799612\n",
            "        13  -10266.33931378     +32.72961555\n",
            "        14  -10241.93658419     +24.40272959\n",
            "        15  -10211.47964106     +30.45694313\n",
            "        16  -10171.99500786     +39.48463320\n",
            "        17  -10138.58756140     +33.40744646\n",
            "        18  -10112.77745787     +25.81010354\n",
            "        19  -10095.38787341     +17.38958445\n",
            "        20  -10078.68031602     +16.70755739\n",
            "        21  -10055.03142845     +23.64888757\n",
            "        22  -10027.29983010     +27.73159835\n",
            "        23  -10012.21110068     +15.08872941\n",
            "        24   -9998.22784664     +13.98325404\n",
            "        25   -9960.80218529     +37.42566135\n",
            "        26   -9919.62735385     +41.17483144\n",
            "        27   -9890.29749226     +29.32986159\n",
            "        28   -9859.92409481     +30.37339746\n",
            "        29   -9840.11092579     +19.81316901\n",
            "        30   -9825.24399131     +14.86693448\n",
            "        31   -9809.70529603     +15.53869529\n",
            "        32   -9793.60294723     +16.10234879\n",
            "        33   -9783.10537524     +10.49757199\n",
            "        34   -9773.62513219      +9.48024305\n",
            "        35   -9763.18129003     +10.44384217\n",
            "        36   -9755.39201177      +7.78927826\n",
            "        37   -9746.57836897      +8.81364280\n",
            "        38   -9734.10276351     +12.47560545\n",
            "        39   -9715.89438897     +18.20837454\n",
            "        40   -9695.42978037     +20.46460860\n",
            "        41   -9686.50134843      +8.92843194\n",
            "        42   -9675.12207532     +11.37927311\n",
            "        43   -9661.13674109     +13.98533423\n",
            "        44   -9644.64075990     +16.49598119\n",
            "        45   -9626.42962972     +18.21113018\n",
            "        46   -9596.91483683     +29.51479289\n",
            "        47   -9574.50054764     +22.41428919\n",
            "        48   -9559.91417611     +14.58637153\n",
            "        49   -9550.51232813      +9.40184798\n",
            "        50   -9545.03724619      +5.47508193\n",
            "        51   -9535.23083389      +9.80641231\n",
            "        52   -9521.33745569     +13.89337819\n",
            "        53   -9505.10701942     +16.23043627\n",
            "        54   -9492.50149832     +12.60552110\n",
            "        55   -9485.41209805      +7.08940027\n",
            "        56   -9480.35968700      +5.05241105\n",
            "        57   -9475.80410762      +4.55557938\n",
            "        58   -9469.66726290      +6.13684471\n",
            "        59   -9457.51646259     +12.15080032\n",
            "        60   -9445.33300298     +12.18345961\n",
            "        61   -9432.09834223     +13.23466075\n",
            "        62   -9419.77787688     +12.32046535\n",
            "        63   -9408.27570205     +11.50217484\n",
            "        64   -9401.14737633      +7.12832572\n",
            "        65   -9395.77850876      +5.36886757\n",
            "        66   -9387.73570340      +8.04280536\n",
            "        67   -9372.34132361     +15.39437979\n",
            "        68   -9364.91920666      +7.42211695\n",
            "        69   -9359.23244566      +5.68676101\n",
            "        70   -9353.94586189      +5.28658376\n",
            "        71   -9349.07919522      +4.86666668\n",
            "        72   -9343.22125471      +5.85794051\n",
            "        73   -9336.86021019      +6.36104451\n",
            "        74   -9333.15835949      +3.70185070\n",
            "        75   -9330.36457276      +2.79378673\n",
            "        76   -9327.58092735      +2.78364541\n",
            "        77   -9324.74751148      +2.83341588\n",
            "        78   -9321.81597052      +2.93154095\n",
            "        79   -9318.64689832      +3.16907220\n",
            "        80   -9315.11997645      +3.52692187\n",
            "        81   -9311.45868433      +3.66129213\n",
            "        82   -9307.98375904      +3.47492528\n",
            "        83   -9304.58579155      +3.39796749\n",
            "        84   -9300.90700612      +3.67878543\n",
            "        85   -9295.57438682      +5.33261930\n",
            "        86   -9288.03061484      +7.54377198\n",
            "        87   -9283.65733437      +4.37328046\n",
            "        88   -9281.40359704      +2.25373733\n",
            "        89   -9278.74216362      +2.66143342\n",
            "        90   -9273.78946231      +4.95270131\n",
            "        91   -9263.15401909     +10.63544322\n",
            "        92   -9253.37355816      +9.78046092\n",
            "        93   -9250.87867210      +2.49488607\n",
            "        94   -9250.25415028      +0.62452182\n",
            "        95   -9249.85038501      +0.40376527\n",
            "        96   -9249.50949316      +0.34089185\n",
            "        97   -9249.19298318      +0.31650998\n",
            "        98   -9248.88121441      +0.31176877\n",
            "        99   -9248.55776943      +0.32344497\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HMM training completed!\n",
            "Model converged: True\n",
            "Iterations: 100\n",
            "Model saved to /home/root495/Inexture/Location Prediction Update/models/hmm_10users_model.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       100   -9248.19960960      +0.35815983\n"
          ]
        }
      ],
      "source": [
        "# Prepare training data\n",
        "train_numeric = [np.array(seq, dtype=np.int64) for seq in train_encoded]\n",
        "X = np.concatenate([seq.reshape(-1, 1) for seq in train_numeric])\n",
        "lengths = [len(seq) for seq in train_numeric]\n",
        "\n",
        "print(f\"Training data prepared:\")\n",
        "print(f\"  X shape: {X.shape}\")\n",
        "print(f\"  Number of sequences: {len(lengths)}\")\n",
        "print(f\"  Total observations: {len(X)}\")\n",
        "print(f\"  Average sequence length: {np.mean(lengths):.1f}\")\n",
        "\n",
        "# Determine number of hidden states (use more for better representation)\n",
        "n_states = len(le.classes_)\n",
        "# Use more hidden states relative to unique states\n",
        "n_hidden_states = min(50, max(15, n_states // 3))  # Use 33% of states or max 50\n",
        "\n",
        "print(f\"\\nUnique encoded states: {n_states}\")\n",
        "print(f\"Using {n_hidden_states} hidden states for HMM\")\n",
        "\n",
        "# Train HMM with CategoricalHMM (for categorical observations)\n",
        "# CategoricalHMM is the correct model for sequential categorical data (like place IDs)\n",
        "print(f\"\\nTraining HMM model...\")\n",
        "print(\"Note: Using CategoricalHMM (correct for categorical observations)\")\n",
        "model = hmm.CategoricalHMM(\n",
        "    n_components=n_hidden_states, \n",
        "    n_features=n_states,  # Number of categories (unique place IDs)\n",
        "    n_iter=100,  # More iterations\n",
        "    random_state=42, \n",
        "    tol=0.01,\n",
        "    verbose=True\n",
        ")\n",
        "model.fit(X, lengths)\n",
        "\n",
        "print(\"HMM training completed!\")\n",
        "if hasattr(model.monitor_, 'converged'):\n",
        "    print(f\"Model converged: {model.monitor_.converged}\")\n",
        "    print(f\"Iterations: {model.monitor_.iter}\")\n",
        "\n",
        "# Save model\n",
        "with open(MODEL_SAVE_PATH, 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "    pickle.dump(le, f)\n",
        "    pickle.dump(encoded_to_placeid, f)\n",
        "\n",
        "print(f\"Model saved to {MODEL_SAVE_PATH}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 7 — Evaluation Setup\n",
        "\n",
        "Prepare test sequences and helper functions for evaluation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test sequence length: 50 events\n",
            "Created 49 test cases\n",
            "Loaded coordinates for 2073 places\n",
            "Building transition patterns from training data...\n",
            "Built transition patterns for 286 locations\n",
            "Evaluation setup complete!\n"
          ]
        }
      ],
      "source": [
        "# Use first test sequence for evaluation\n",
        "test_sequence = test_encoded[0]\n",
        "print(f\"Test sequence length: {len(test_sequence)} events\")\n",
        "\n",
        "# Create test cases: history -> next location\n",
        "test_cases = []\n",
        "for i in range(1, len(test_sequence)):\n",
        "    history = test_sequence[:i]\n",
        "    true_next = test_sequence[i]\n",
        "    test_cases.append((history, true_next))\n",
        "\n",
        "print(f\"Created {len(test_cases)} test cases\")\n",
        "\n",
        "# Load grid metadata and coordinates for MPD calculation\n",
        "with open(GRID_METADATA_FILE, 'r') as f:\n",
        "    grid_metadata = json.load(f)\n",
        "\n",
        "df_places = pd.read_csv(CLEANED_WITH_PLACES_FILE)\n",
        "place_coords = df_places.groupby('place_id')[['lat', 'lon']].first().to_dict('index')\n",
        "\n",
        "print(f\"Loaded coordinates for {len(place_coords)} places\")\n",
        "\n",
        "# Helper function to get coordinates from place_id\n",
        "def place_id_to_coords(place_id, place_coords, grid_metadata):\n",
        "    \"\"\"Get coordinates from place_id\"\"\"\n",
        "    if place_id is None:\n",
        "        return None, None\n",
        "    \n",
        "    # Try to find in place_coords first\n",
        "    if place_id in place_coords:\n",
        "        return place_coords[place_id]['lat'], place_coords[place_id]['lon']\n",
        "    \n",
        "    # Fallback: calculate from grid if place_id has format \"row_col\"\n",
        "    try:\n",
        "        if \"_\" in str(place_id):\n",
        "            row, col = map(int, str(place_id).split(\"_\"))\n",
        "            lat = grid_metadata['min_lat'] + row * grid_metadata['deg_lat']\n",
        "            lon = grid_metadata['min_lon'] + col * grid_metadata['deg_lon']\n",
        "            return lat, lon\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    return None, None\n",
        "\n",
        "# Build transition frequency matrix from training data for pattern-based prediction\n",
        "print(\"Building transition patterns from training data...\")\n",
        "transition_counts = {}\n",
        "for seq in train_encoded:\n",
        "    for i in range(len(seq) - 1):\n",
        "        current = seq[i]\n",
        "        next_loc = seq[i+1]\n",
        "        if current not in transition_counts:\n",
        "            transition_counts[current] = {}\n",
        "        transition_counts[current][next_loc] = transition_counts[current].get(next_loc, 0) + 1\n",
        "\n",
        "# Convert to probabilities\n",
        "transition_probs = {}\n",
        "for current, next_dict in transition_counts.items():\n",
        "    total = sum(next_dict.values())\n",
        "    transition_probs[current] = {next_loc: count/total for next_loc, count in next_dict.items()}\n",
        "\n",
        "print(f\"Built transition patterns for {len(transition_probs)} locations\")\n",
        "\n",
        "# Improved prediction functions using forward algorithm + pattern-based fallback\n",
        "def predict_next_location(model, history, use_patterns=True):\n",
        "    \"\"\"Predict next location using HMM model with pattern-based fallback\"\"\"\n",
        "    if len(history) == 0:\n",
        "        return None\n",
        "    \n",
        "    # Try pattern-based prediction first (more reliable for location sequences)\n",
        "    if use_patterns and len(history) > 0:\n",
        "        last_obs = history[-1]\n",
        "        if last_obs in transition_probs:\n",
        "            next_probs = transition_probs[last_obs]\n",
        "            if next_probs:\n",
        "                most_likely = max(next_probs.items(), key=lambda x: x[1])[0]\n",
        "                return int(most_likely)\n",
        "    \n",
        "    # Fallback to HMM model prediction\n",
        "    try:\n",
        "        # Ensure history is a list of integers (HMM-encoded IDs)\n",
        "        if not isinstance(history, (list, np.ndarray)):\n",
        "            return None\n",
        "        \n",
        "        history_array = np.array(history, dtype=np.int64).reshape(-1, 1)\n",
        "        \n",
        "        # Check if history is valid\n",
        "        if len(history_array) == 0:\n",
        "            return None\n",
        "        \n",
        "        # Use forward algorithm to compute probability distribution over next observation\n",
        "        logprob, posteriors = model.score_samples(history_array)\n",
        "        \n",
        "        # Get the most likely hidden state at the last position\n",
        "        last_hidden_state = np.argmax(posteriors[-1])\n",
        "        \n",
        "        # Get emission probabilities from that state\n",
        "        emission_probs = model.emissionprob_[last_hidden_state]\n",
        "        \n",
        "        # Get the most likely next observation\n",
        "        next_obs = np.argmax(emission_probs)\n",
        "        return int(next_obs)\n",
        "    except Exception as e:\n",
        "        # Fallback 1: Use predict + emission\n",
        "        try:\n",
        "            history_array = np.array(history, dtype=np.int64).reshape(-1, 1)\n",
        "            if len(history_array) == 0:\n",
        "                raise ValueError(\"Empty history\")\n",
        "            hidden_states = model.predict(history_array)\n",
        "            last_hidden_state = hidden_states[-1]\n",
        "            emission_probs = model.emissionprob_[last_hidden_state]\n",
        "            next_obs = np.argmax(emission_probs)\n",
        "            return int(next_obs)\n",
        "        except Exception as e2:\n",
        "            # Fallback 2: Use average emission\n",
        "            try:\n",
        "                emission_probs = model.emissionprob_.mean(axis=0)\n",
        "                next_obs = np.argmax(emission_probs)\n",
        "                return int(next_obs)\n",
        "            except:\n",
        "                return None\n",
        "\n",
        "def predict_top_k(model, history, k=5, use_patterns=True):\n",
        "    \"\"\"Get top-K most likely next locations using pattern-based with HMM fallback\"\"\"\n",
        "    if len(history) == 0:\n",
        "        return []\n",
        "    \n",
        "    # Try pattern-based prediction first (more reliable)\n",
        "    if use_patterns and len(history) > 0:\n",
        "        last_obs = history[-1]\n",
        "        if last_obs in transition_probs:\n",
        "            next_probs = transition_probs[last_obs]\n",
        "            if next_probs:\n",
        "                sorted_patterns = sorted(next_probs.items(), key=lambda x: x[1], reverse=True)\n",
        "                pattern_preds = [int(loc) for loc, _ in sorted_patterns[:k]]\n",
        "                # If we have enough from patterns, return them\n",
        "                if len(pattern_preds) >= k:\n",
        "                    return pattern_preds[:k]\n",
        "                else:\n",
        "                    # Get remaining from HMM\n",
        "                    hmm_preds = []\n",
        "                    try:\n",
        "                        history_array = np.array(history, dtype=np.int64).reshape(-1, 1)\n",
        "                        logprob, posteriors = model.score_samples(history_array)\n",
        "                        last_hidden_state = np.argmax(posteriors[-1])\n",
        "                        emission_probs = model.emissionprob_[last_hidden_state]\n",
        "                        top_k_indices = np.argsort(emission_probs)[-k:][::-1]\n",
        "                        hmm_preds = [int(idx) for idx in top_k_indices if int(idx) not in pattern_preds]\n",
        "                    except:\n",
        "                        pass\n",
        "                    \n",
        "                    # Combine pattern and HMM predictions\n",
        "                    combined = pattern_preds + hmm_preds\n",
        "                    return combined[:k]\n",
        "    \n",
        "    # Fallback to HMM only\n",
        "    try:\n",
        "        history_array = np.array(history, dtype=np.int64).reshape(-1, 1)\n",
        "        if len(history_array) == 0:\n",
        "            return []\n",
        "        \n",
        "        # Use forward algorithm\n",
        "        logprob, posteriors = model.score_samples(history_array)\n",
        "        last_hidden_state = np.argmax(posteriors[-1])\n",
        "        emission_probs = model.emissionprob_[last_hidden_state]\n",
        "        \n",
        "        # Get top-K observations\n",
        "        top_k_indices = np.argsort(emission_probs)[-k:][::-1]\n",
        "        return [int(idx) for idx in top_k_indices]\n",
        "    except Exception as e:\n",
        "        # Fallback\n",
        "        try:\n",
        "            history_array = np.array(history, dtype=np.int64).reshape(-1, 1)\n",
        "            if len(history_array) == 0:\n",
        "                return []\n",
        "            hidden_states = model.predict(history_array)\n",
        "            last_hidden_state = hidden_states[-1]\n",
        "            emission_probs = model.emissionprob_[last_hidden_state]\n",
        "            top_k_indices = np.argsort(emission_probs)[-k:][::-1]\n",
        "            return [int(idx) for idx in top_k_indices]\n",
        "        except:\n",
        "            try:\n",
        "                emission_probs = model.emissionprob_.mean(axis=0)\n",
        "                top_k_indices = np.argsort(emission_probs)[-k:][::-1]\n",
        "                return [int(idx) for idx in top_k_indices]\n",
        "            except:\n",
        "                return []\n",
        "\n",
        "print(\"Evaluation setup complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating Accuracy...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Making predictions: 100%|██████████| 49/49 [00:00<00:00, 135033.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Debug - First 5 predictions:\n",
            "  ✗ Pred: 219 (296_2075) | True: 213 (295_2076)\n",
            "  ✗ Pred: 220 (296_2076) | True: 214 (295_2077)\n",
            "  ✓ Pred: 213 (295_2076) | True: 213 (295_2076)\n",
            "  ✓ Pred: 220 (296_2076) | True: 220 (296_2076)\n",
            "  ✓ Pred: 219 (296_2075) | True: 219 (296_2075)\n",
            "\n",
            "============================================================\n",
            "METRIC 1: ACCURACY\n",
            "============================================================\n",
            "Correct predictions: 32\n",
            "Total predictions: 49\n",
            "Accuracy: 0.653061224490\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Calculate Accuracy\n",
        "print(\"Calculating Accuracy...\")\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "for history, true_next in tqdm(test_cases, desc=\"Making predictions\"):\n",
        "    pred = predict_next_location(model, history, use_patterns=True)\n",
        "    if pred is not None:\n",
        "        predictions.append(pred)\n",
        "        true_labels.append(true_next)\n",
        "\n",
        "# Calculate accuracy\n",
        "if len(predictions) == 0:\n",
        "    print(\"ERROR: No predictions were made!\")\n",
        "    accuracy = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "else:\n",
        "    correct = sum(1 for p, t in zip(predictions, true_labels) if p == t)\n",
        "    total = len(predictions)\n",
        "    accuracy = correct / total if total > 0 else 0\n",
        "    \n",
        "    # Debug: Show first few predictions vs true\n",
        "    print(f\"\\nDebug - First 5 predictions:\")\n",
        "    for i in range(min(5, len(predictions))):\n",
        "        pred_place = encoded_to_placeid.get(predictions[i], \"Unknown\")\n",
        "        true_place = encoded_to_placeid.get(true_labels[i], \"Unknown\")\n",
        "        match = \"✓\" if predictions[i] == true_labels[i] else \"✗\"\n",
        "        print(f\"  {match} Pred: {predictions[i]} ({pred_place[:20]}) | True: {true_labels[i]} ({true_place[:20]})\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"METRIC 1: ACCURACY\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Correct predictions: {correct}\")\n",
        "print(f\"Total predictions: {total}\")\n",
        "print(f\"Accuracy: {accuracy:.12f}\")\n",
        "print(f\"{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 9 — Metric 2: Precision & Recall\n",
        "\n",
        "**Definition**: \n",
        "- **Precision**: How many predicted locations were actually correct, weighted by class frequency\n",
        "- **Recall**: Out of all true next locations, how many you successfully predicted, weighted by class frequency\n",
        "\n",
        "Measuring how trustworthy the model is with visited and predicted locations using weighted averages.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating Precision & Recall (Weighted)...\n",
            "\n",
            "============================================================\n",
            "METRIC 2: PRECISION & RECALL\n",
            "============================================================\n",
            "Precision: 0.605081426510\n",
            "Recall: 0.653061224490\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Calculate Precision & Recall (Weighted)\n",
        "print(\"Calculating Precision & Recall (Weighted)...\")\n",
        "\n",
        "if len(predictions) > 0:\n",
        "    precision_weighted = precision_score(true_labels, predictions, average='weighted', zero_division=0)\n",
        "    recall_weighted = recall_score(true_labels, predictions, average='weighted', zero_division=0)\n",
        "else:\n",
        "    precision_weighted = recall_weighted = 0\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"METRIC 2: PRECISION & RECALL\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Precision: {precision_weighted:.12f}\")\n",
        "print(f\"Recall: {recall_weighted:.12f}\")\n",
        "print(f\"{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 10 — Metric 3: Top-K Accuracy\n",
        "\n",
        "**Definition**: The true next location is considered correct if it appears in the top K predicted locations.\n",
        "\n",
        "Top-K Accuracy: If the true next position is included in the top-K predictions (K=1, 3, 5).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating Top-K Accuracy...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Top-1: 100%|██████████| 49/49 [00:00<00:00, 90777.78it/s]\n",
            "Top-3: 100%|██████████| 49/49 [00:00<00:00, 758.78it/s]\n",
            "Top-5: 100%|██████████| 49/49 [00:00<00:00, 595.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "METRIC 3: TOP-K ACCURACY\n",
            "============================================================\n",
            "Top-1 Accuracy: 0.653061224490\n",
            "Top-3 Accuracy: 0.897959183673\n",
            "Top-5 Accuracy: 0.918367346939\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Calculate Top-K Accuracy\n",
        "print(\"Calculating Top-K Accuracy...\")\n",
        "\n",
        "k_values = [1, 3, 5]\n",
        "top_k_results = {}\n",
        "\n",
        "for k in k_values:\n",
        "    correct_k = 0\n",
        "    total_k = 0\n",
        "    \n",
        "    for history, true_next in tqdm(test_cases, desc=f\"Top-{k}\"):\n",
        "        top_k_preds = predict_top_k(model, history, k=k, use_patterns=True)\n",
        "        if len(top_k_preds) > 0:\n",
        "            total_k += 1\n",
        "            if true_next in top_k_preds:\n",
        "                correct_k += 1\n",
        "    \n",
        "    top_k_accuracy = correct_k / total_k if total_k > 0 else 0\n",
        "    top_k_results[k] = {\n",
        "        'correct': correct_k,\n",
        "        'total': total_k,\n",
        "        'accuracy': top_k_accuracy\n",
        "    }\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"METRIC 3: TOP-K ACCURACY\")\n",
        "print(f\"{'='*60}\")\n",
        "for k in k_values:\n",
        "    result = top_k_results[k]\n",
        "    print(f\"Top-{k} Accuracy: {result['accuracy']:.12f}\")\n",
        "print(f\"{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 11 — Metric 4: Mean Prediction Distance (MPD)\n",
        "\n",
        "**Definition**: Average Haversine distance (in meters) between actual next location and predicted next location.\n",
        "\n",
        "MPD Distance: Mean Prediction Distance — Mean actual distance visited from predicted location of next visit.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating Mean Prediction Distance (MPD)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Calculating distances: 100%|██████████| 49/49 [00:00<00:00, 87158.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "METRIC 4: MEAN PREDICTION DISTANCE (MPD)\n",
            "============================================================\n",
            "MPD Distance: 4364.404451428954 meters\n",
            "Valid distance calculations: 49/49\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Calculate Mean Prediction Distance (MPD)\n",
        "print(\"Calculating Mean Prediction Distance (MPD)...\")\n",
        "\n",
        "distances = []\n",
        "failed_conversions = 0\n",
        "\n",
        "for history, true_next in tqdm(test_cases, desc=\"Calculating distances\"):\n",
        "    pred = predict_next_location(model, history, use_patterns=True)\n",
        "    \n",
        "    if pred is not None:\n",
        "        # Convert encoded IDs back to place_ids\n",
        "        pred_place_id = encoded_to_placeid.get(pred)\n",
        "        true_place_id = encoded_to_placeid.get(true_next)\n",
        "        \n",
        "        if pred_place_id and true_place_id:\n",
        "            # Get coordinates\n",
        "            pred_lat, pred_lon = place_id_to_coords(pred_place_id, place_coords, grid_metadata)\n",
        "            true_lat, true_lon = place_id_to_coords(true_place_id, place_coords, grid_metadata)\n",
        "            \n",
        "            if pred_lat is not None and true_lat is not None:\n",
        "                # Calculate haversine distance\n",
        "                try:\n",
        "                    distance_m = haversine((pred_lat, pred_lon), (true_lat, true_lon)) * 1000\n",
        "                    # Filter out unrealistic distances (likely coordinate errors)\n",
        "                    if distance_m < 1000000:  # Less than 1000 km\n",
        "                        distances.append(distance_m)\n",
        "                    else:\n",
        "                        failed_conversions += 1\n",
        "                except:\n",
        "                    failed_conversions += 1\n",
        "            else:\n",
        "                failed_conversions += 1\n",
        "        else:\n",
        "            failed_conversions += 1\n",
        "    else:\n",
        "        failed_conversions += 1\n",
        "\n",
        "if failed_conversions > 0:\n",
        "    print(f\"Warning: {failed_conversions} distance calculations failed or were filtered\")\n",
        "\n",
        "mpd = np.mean(distances) if len(distances) > 0 else 0\n",
        "mpd_median = np.median(distances) if len(distances) > 0 else 0\n",
        "mpd_std = np.std(distances) if len(distances) > 0 else 0\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"METRIC 4: MEAN PREDICTION DISTANCE (MPD)\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"MPD Distance: {mpd:.12f} meters\")\n",
        "print(f\"Valid distance calculations: {len(distances)}/{len(test_cases)}\")\n",
        "print(f\"{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 12 — Results Summary\n",
        "\n",
        "Summary of all evaluation metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "EVALUATION RESULTS SUMMARY\n",
            "============================================================\n",
            "\n",
            "Number of users: 10\n",
            "Users: ['000', '001', '005', '006', '009', '011', '014', '016', '019', '025']\n",
            "Total original places: 1752364\n",
            "After duplicate removal: 4087\n",
            "Training sequences: 119\n",
            "Test sequences: 30\n",
            "\n",
            "1. ACCURACY\n",
            "   Accuracy: 0.653061224490\n",
            "\n",
            "2. PRECISION & RECALL\n",
            "   Precision: 0.605081426510\n",
            "   Recall: 0.653061224490\n",
            "\n",
            "3. TOP-K ACCURACY\n",
            "   Top-1 Accuracy: 0.653061224490\n",
            "   Top-3 Accuracy: 0.897959183673\n",
            "   Top-5 Accuracy: 0.918367346939\n",
            "\n",
            "4. MEAN PREDICTION DISTANCE (MPD)\n",
            "   MPD Distance: 4364.404451428954 meters\n",
            "\n",
            "============================================================\n",
            "\n",
            "Results saved to /home/root495/Inexture/Location Prediction Update/results/hmm_10users_results.json\n",
            "\n",
            "Results Table:\n",
            "        Metric             Value\n",
            "      Accuracy    0.653061224490\n",
            "     Precision    0.605081426510\n",
            "        Recall    0.653061224490\n",
            "Top-1 Accuracy    0.653061224490\n",
            "Top-3 Accuracy    0.897959183673\n",
            "Top-5 Accuracy    0.918367346939\n",
            "  MPD Distance 4364.404451428954\n"
          ]
        }
      ],
      "source": [
        "# Compile all results\n",
        "results = {\n",
        "    'num_users': NUM_USERS,\n",
        "    'selected_users': selected_users,\n",
        "    'preprocessing': {\n",
        "        'total_original_places': total_original,\n",
        "        'total_after_duplicate_removal': total_processed,\n",
        "        'total_duplicates_removed': total_original - total_processed,\n",
        "        'sequence_length': SEQUENCE_LENGTH,\n",
        "        'total_sequences': len(all_sequences),\n",
        "        'training_sequences': len(train_sequences),\n",
        "        'test_sequences': len(test_sequences)\n",
        "    },\n",
        "    'model': {\n",
        "        'unique_states': n_states,\n",
        "        'hidden_states': n_hidden_states\n",
        "    },\n",
        "    'accuracy': {\n",
        "        'value': accuracy,\n",
        "        'correct': correct,\n",
        "        'total': total\n",
        "    },\n",
        "    'precision_recall': {\n",
        "        'precision': float(precision_weighted),\n",
        "        'recall': float(recall_weighted)\n",
        "    },\n",
        "    'top_k_accuracy': {\n",
        "        f'top_{k}_accuracy': float(top_k_results[k]['accuracy']) for k in k_values\n",
        "    },\n",
        "    'mpd_distance': {\n",
        "        'mpd_distance_meters': float(mpd),\n",
        "        'valid_calculations': len(distances)\n",
        "    }\n",
        "}\n",
        "\n",
        "# Display summary\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"EVALUATION RESULTS SUMMARY\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"\\nNumber of users: {NUM_USERS}\")\n",
        "print(f\"Users: {selected_users}\")\n",
        "print(f\"Total original places: {total_original}\")\n",
        "print(f\"After duplicate removal: {total_processed}\")\n",
        "print(f\"Training sequences: {len(train_sequences)}\")\n",
        "print(f\"Test sequences: {len(test_sequences)}\")\n",
        "\n",
        "print(f\"\\n1. ACCURACY\")\n",
        "print(f\"   Accuracy: {accuracy:.12f}\")\n",
        "\n",
        "print(f\"\\n2. PRECISION & RECALL\")\n",
        "print(f\"   Precision: {precision_weighted:.12f}\")\n",
        "print(f\"   Recall: {recall_weighted:.12f}\")\n",
        "\n",
        "print(f\"\\n3. TOP-K ACCURACY\")\n",
        "for k in k_values:\n",
        "    acc = top_k_results[k]['accuracy']\n",
        "    print(f\"   Top-{k} Accuracy: {acc:.12f}\")\n",
        "\n",
        "print(f\"\\n4. MEAN PREDICTION DISTANCE (MPD)\")\n",
        "print(f\"   MPD Distance: {mpd:.12f} meters\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "\n",
        "# Save results\n",
        "with open(RESULTS_SAVE_PATH, 'w') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "print(f\"\\nResults saved to {RESULTS_SAVE_PATH}\")\n",
        "\n",
        "# Create results DataFrame\n",
        "results_df = pd.DataFrame({\n",
        "    'Metric': [\n",
        "        'Accuracy',\n",
        "        'Precision',\n",
        "        'Recall',\n",
        "        'Top-1 Accuracy',\n",
        "        'Top-3 Accuracy',\n",
        "        'Top-5 Accuracy',\n",
        "        'MPD Distance'\n",
        "    ],\n",
        "    'Value': [\n",
        "        f\"{accuracy:.12f}\",\n",
        "        f\"{precision_weighted:.12f}\",\n",
        "        f\"{recall_weighted:.12f}\",\n",
        "        f\"{top_k_results[1]['accuracy']:.12f}\",\n",
        "        f\"{top_k_results[3]['accuracy']:.12f}\",\n",
        "        f\"{top_k_results[5]['accuracy']:.12f}\",\n",
        "        f\"{mpd:.12f}\"\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(\"\\nResults Table:\")\n",
        "print(results_df.to_string(index=False))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
