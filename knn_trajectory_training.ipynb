{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# KNN Trajectory Training on 10 Users' Trajectories\n",
        "\n",
        "This notebook:\n",
        "- Loads 10 users' trajectories (same as HMM/GNN/Fusion/Markov Chain models)\n",
        "- Removes consecutive duplicates (AAABCDCCABB → ABCDCAB) for each user\n",
        "- Creates sequences of length 50 from all users\n",
        "- Trains a K-Nearest Neighbors (KNN) trajectory model using sequence similarity\n",
        "- Evaluates all 4 metrics: Accuracy, Precision & Recall, Top-K Accuracy, MPD\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1 — Imports & Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "from haversine import haversine\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from collections import defaultdict, Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds\n",
        "np.random.seed(42)\n",
        "\n",
        "# Paths\n",
        "BASE_PATH = \"/home/root495/Inexture/Location Prediction Update\"\n",
        "PROCESSED_PATH = BASE_PATH + \"/data/processed/\"\n",
        "SEQUENCES_FILE = PROCESSED_PATH + \"place_sequences.json\"\n",
        "GRID_METADATA_FILE = PROCESSED_PATH + \"grid_metadata.json\"\n",
        "CLEANED_WITH_PLACES_FILE = PROCESSED_PATH + \"cleaned_with_places.csv\"\n",
        "OUTPUT_PATH = BASE_PATH + \"/notebooks/\"\n",
        "MODELS_PATH = BASE_PATH + \"/models/\"\n",
        "RESULTS_PATH = BASE_PATH + \"/results/\"\n",
        "MODEL_SAVE_PATH = MODELS_PATH + \"knn_trajectory_model.pkl\"\n",
        "RESULTS_SAVE_PATH = RESULTS_PATH + \"knn_trajectory_results.json\"\n",
        "\n",
        "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "os.makedirs(MODELS_PATH, exist_ok=True)\n",
        "os.makedirs(RESULTS_PATH, exist_ok=True)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 2 — Load 10 Users' Trajectories\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading place sequences...\n",
            "Total users available: 54\n",
            "\n",
            "Selected 10 users: ['000', '001', '005', '006', '009', '011', '014', '016', '019', '025']\n",
            "  User 000: 173817 places\n",
            "  User 001: 108561 places\n",
            "  User 005: 108967 places\n",
            "  User 006: 31809 places\n",
            "  User 009: 84573 places\n",
            "  User 011: 90770 places\n",
            "  User 014: 388051 places\n",
            "  User 016: 89208 places\n",
            "  User 019: 47792 places\n",
            "  User 025: 628816 places\n",
            "\n",
            "Total places across all 10 users: 1752364\n"
          ]
        }
      ],
      "source": [
        "# Load place sequences\n",
        "print(\"Loading place sequences...\")\n",
        "with open(SEQUENCES_FILE, 'r') as f:\n",
        "    sequences_dict = json.load(f)\n",
        "\n",
        "print(f\"Total users available: {len(sequences_dict)}\")\n",
        "\n",
        "# Select first 10 users (same as HMM/GNN/Fusion/Markov Chain models)\n",
        "user_ids = list(sequences_dict.keys())\n",
        "NUM_USERS = 10\n",
        "selected_users = user_ids[:NUM_USERS]\n",
        "\n",
        "print(f\"\\nSelected {NUM_USERS} users: {selected_users}\")\n",
        "\n",
        "# Load sequences for all selected users\n",
        "user_sequences = {}\n",
        "total_places = 0\n",
        "for user_id in selected_users:\n",
        "    seq = sequences_dict[user_id]\n",
        "    user_sequences[user_id] = seq\n",
        "    total_places += len(seq)\n",
        "    print(f\"  User {user_id}: {len(seq)} places\")\n",
        "\n",
        "print(f\"\\nTotal places across all {NUM_USERS} users: {total_places}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 3 — Preprocess: Remove Consecutive Duplicates\n",
        "\n",
        "Remove consecutive duplicate locations for each user. Example: AAABCDCCABB → ABCDCAB\n",
        "\n",
        "Only consecutive duplicates are removed. If a location appears again later (non-consecutive), it is kept.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing users...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Removing duplicates:   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  User 000: 173817 → 795 places (99.5% reduction)\n",
            "  User 001: 108561 → 186 places (99.8% reduction)\n",
            "  User 005: 108967 → 283 places (99.7% reduction)\n",
            "  User 006: 31809 → 103 places (99.7% reduction)\n",
            "  User 009: 84573 → 17 places (100.0% reduction)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Removing duplicates:  70%|███████   | 7/10 [00:00<00:00, 51.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  User 011: 90770 → 125 places (99.9% reduction)\n",
            "  User 014: 388051 → 766 places (99.8% reduction)\n",
            "  User 016: 89208 → 124 places (99.9% reduction)\n",
            "  User 019: 47792 → 120 places (99.7% reduction)\n",
            "  User 025: 628816 → 1568 places (99.8% reduction)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Removing duplicates: 100%|██████████| 10/10 [00:00<00:00, 41.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Summary:\n",
            "  Total original places: 1752364\n",
            "  Total after processing: 4087\n",
            "  Total duplicates removed: 1748277 (99.8%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def remove_consecutive_duplicates(sequence):\n",
        "    \"\"\"\n",
        "    Remove consecutive duplicates from sequence.\n",
        "    Example: [A, A, A, B, C, D, C, C, A, B, B] → [A, B, C, D, C, A, B]\n",
        "    \"\"\"\n",
        "    if len(sequence) == 0:\n",
        "        return sequence\n",
        "    \n",
        "    processed = [sequence[0]]  # Always keep first element\n",
        "    \n",
        "    for i in range(1, len(sequence)):\n",
        "        # Only add if different from previous (not consecutive duplicate)\n",
        "        if sequence[i] != sequence[i-1]:\n",
        "            processed.append(sequence[i])\n",
        "    \n",
        "    return processed\n",
        "\n",
        "# Apply consecutive duplicate removal to each user\n",
        "processed_sequences = {}\n",
        "total_original = 0\n",
        "total_processed = 0\n",
        "\n",
        "print(\"Processing users...\")\n",
        "for user_id in tqdm(selected_users, desc=\"Removing duplicates\"):\n",
        "    original_seq = user_sequences[user_id]\n",
        "    processed_seq = remove_consecutive_duplicates(original_seq)\n",
        "    processed_sequences[user_id] = processed_seq\n",
        "    \n",
        "    original_len = len(original_seq)\n",
        "    processed_len = len(processed_seq)\n",
        "    total_original += original_len\n",
        "    total_processed += processed_len\n",
        "    \n",
        "    reduction = original_len - processed_len\n",
        "    reduction_pct = (reduction / original_len * 100) if original_len > 0 else 0\n",
        "    print(f\"  User {user_id}: {original_len} → {processed_len} places ({reduction_pct:.1f}% reduction)\")\n",
        "\n",
        "print(f\"\\nSummary:\")\n",
        "print(f\"  Total original places: {total_original}\")\n",
        "print(f\"  Total after processing: {total_processed}\")\n",
        "print(f\"  Total duplicates removed: {total_original - total_processed} ({((total_original - total_processed)/total_original*100):.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 4 — Create Sequences of Length 50\n",
        "\n",
        "Split each user's processed sequence into fixed-length chunks of 50 events each.\n",
        "Combine sequences from all users for training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating sequences from all users...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing users: 100%|██████████| 10/10 [00:00<00:00, 6956.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  User 000: 30 sequences\n",
            "  User 001: 6 sequences\n",
            "  User 005: 10 sequences\n",
            "  User 006: 3 sequences\n",
            "  User 009: 0 sequences\n",
            "  User 011: 4 sequences\n",
            "  User 014: 29 sequences\n",
            "  User 016: 3 sequences\n",
            "  User 019: 3 sequences\n",
            "  User 025: 61 sequences\n",
            "\n",
            "Total sequences created: 149\n",
            "Total events in sequences: 7450\n",
            "\n",
            "Training sequences: 119\n",
            "Test sequences: 30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Create sequences of fixed length 50\n",
        "SEQUENCE_LENGTH = 50\n",
        "\n",
        "# Use sliding windows for more training data (overlap helps with learning)\n",
        "# Create overlapping sequences with step size of 25 (50% overlap)\n",
        "all_sequences = []\n",
        "step_size = 25  # Overlap of 50%\n",
        "\n",
        "print(\"Creating sequences from all users...\")\n",
        "for user_id in tqdm(selected_users, desc=\"Processing users\"):\n",
        "    processed_seq = processed_sequences[user_id]\n",
        "    user_sequences_list = []\n",
        "    \n",
        "    for i in range(0, len(processed_seq) - SEQUENCE_LENGTH + 1, step_size):\n",
        "        chunk = processed_seq[i:i+SEQUENCE_LENGTH]\n",
        "        if len(chunk) == SEQUENCE_LENGTH:  # Only full-length sequences\n",
        "            user_sequences_list.append(chunk)\n",
        "    \n",
        "    all_sequences.extend(user_sequences_list)\n",
        "    print(f\"  User {user_id}: {len(user_sequences_list)} sequences\")\n",
        "\n",
        "print(f\"\\nTotal sequences created: {len(all_sequences)}\")\n",
        "print(f\"Total events in sequences: {sum(len(s) for s in all_sequences)}\")\n",
        "\n",
        "# Split into train/test (80/20)\n",
        "split_idx = int(len(all_sequences) * 0.8)\n",
        "train_sequences = all_sequences[:split_idx]\n",
        "test_sequences = all_sequences[split_idx:]\n",
        "\n",
        "print(f\"\\nTraining sequences: {len(train_sequences)}\")\n",
        "print(f\"Test sequences: {len(test_sequences)}\")\n",
        "\n",
        "if len(test_sequences) == 0:\n",
        "    # If no test sequences, use last training sequence for testing\n",
        "    test_sequences = [train_sequences[-1]]\n",
        "    train_sequences = train_sequences[:-1]\n",
        "    print(f\"Adjusted: Training={len(train_sequences)}, Test=1 (using last training sequence)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 5 — Encode Sequences\n",
        "\n",
        "Encode place_ids to integers for KNN trajectory training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding sequences...\n",
            "Unique places across all users: 303\n",
            "Encoded 119 training sequences\n",
            "Encoded 30 test sequences\n",
            "Created mapping for 303 place IDs\n"
          ]
        }
      ],
      "source": [
        "# Encode sequences to integers\n",
        "print(\"Encoding sequences...\")\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Flatten all sequences for encoding\n",
        "all_places = [place for seq in train_sequences + test_sequences for place in seq]\n",
        "le.fit(all_places)\n",
        "\n",
        "n_states = len(le.classes_)\n",
        "print(f\"Unique places across all users: {n_states}\")\n",
        "\n",
        "# Encode training sequences\n",
        "train_encoded = []\n",
        "for seq in train_sequences:\n",
        "    encoded = le.transform(seq).tolist()\n",
        "    train_encoded.append(encoded)\n",
        "\n",
        "# Encode test sequences\n",
        "test_encoded = []\n",
        "for seq in test_sequences:\n",
        "    encoded = le.transform(seq).tolist()\n",
        "    test_encoded.append(encoded)\n",
        "\n",
        "print(f\"Encoded {len(train_encoded)} training sequences\")\n",
        "print(f\"Encoded {len(test_encoded)} test sequences\")\n",
        "\n",
        "# Create mapping from encoded ID to original place_id for coordinate lookup\n",
        "encoded_to_placeid = {}\n",
        "for place_id in le.classes_:\n",
        "    encoded_id = le.transform([place_id])[0]\n",
        "    encoded_to_placeid[int(encoded_id)] = place_id\n",
        "\n",
        "print(f\"Created mapping for {len(encoded_to_placeid)} place IDs\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 6 — Build KNN Trajectory Model\n",
        "\n",
        "Store all training sequences as reference trajectories and implement similarity functions.\n",
        "\n",
        "The KNN model finds k nearest neighbor sequences based on:\n",
        "- Longest Common Prefix (LCP): How many locations match from the start\n",
        "- Sequence similarity: Weighted by position (earlier matches more important)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building KNN Trajectory Model...\n",
            "Storing 119 training sequences as reference trajectories\n",
            "Reference trajectories stored: 119\n",
            "Calculating state frequencies for fallback...\n",
            "Most frequent state: 220 (count: 1602)\n",
            "\n",
            "KNN Trajectory Model built successfully!\n",
            "Similarity functions:\n",
            "  - longest_common_prefix(): Find matching prefix length\n",
            "  - sequence_similarity(): Calculate weighted similarity score\n",
            "  - find_k_nearest(): Find k most similar sequences\n"
          ]
        }
      ],
      "source": [
        "# KNN Configuration\n",
        "K_NEIGHBORS = 5  # Number of nearest neighbors to consider\n",
        "\n",
        "print(\"Building KNN Trajectory Model...\")\n",
        "print(f\"Storing {len(train_encoded)} training sequences as reference trajectories\")\n",
        "\n",
        "# Store all training sequences\n",
        "reference_sequences = train_encoded.copy()\n",
        "print(f\"Reference trajectories stored: {len(reference_sequences)}\")\n",
        "\n",
        "# Calculate state frequencies for fallback\n",
        "print(\"Calculating state frequencies for fallback...\")\n",
        "state_counts = Counter()\n",
        "for seq in train_encoded:\n",
        "    for state in seq:\n",
        "        state_counts[state] += 1\n",
        "\n",
        "most_frequent_state = state_counts.most_common(1)[0][0] if state_counts else None\n",
        "print(f\"Most frequent state: {most_frequent_state} (count: {state_counts[most_frequent_state]})\")\n",
        "\n",
        "\n",
        "def longest_common_prefix(seq1, seq2):\n",
        "    \"\"\"\n",
        "    Find the length of the longest common prefix between two sequences.\n",
        "    \"\"\"\n",
        "    min_len = min(len(seq1), len(seq2))\n",
        "    lcp = 0\n",
        "    for i in range(min_len):\n",
        "        if seq1[i] == seq2[i]:\n",
        "            lcp += 1\n",
        "        else:\n",
        "            break\n",
        "    return lcp\n",
        "\n",
        "\n",
        "def sequence_similarity(query, reference):\n",
        "    \"\"\"\n",
        "    Calculate similarity score between query history and reference sequence.\n",
        "    \n",
        "    Uses longest common prefix with position weighting:\n",
        "    - Earlier matches are more important\n",
        "    - Score = sum of (match_score / position) for matching positions\n",
        "    \n",
        "    Args:\n",
        "        query: List of encoded states (history)\n",
        "        reference: List of encoded states (reference sequence)\n",
        "    \n",
        "    Returns:\n",
        "        Similarity score (higher = more similar)\n",
        "    \"\"\"\n",
        "    if len(query) == 0:\n",
        "        return 0.0\n",
        "    \n",
        "    # Find longest common prefix\n",
        "    lcp = longest_common_prefix(query, reference)\n",
        "    \n",
        "    if lcp == 0:\n",
        "        return 0.0\n",
        "    \n",
        "    # Calculate weighted similarity score\n",
        "    # Weight by position: earlier matches more important\n",
        "    # Score = sum of (1.0 / (position + 1)) for each match\n",
        "    score = 0.0\n",
        "    for i in range(lcp):\n",
        "        if query[i] == reference[i]:\n",
        "            # Position weight: earlier positions have higher weight\n",
        "            position_weight = 1.0 / (i + 1)\n",
        "            score += position_weight\n",
        "    \n",
        "    # Normalize by query length to get score in [0, 1] range\n",
        "    max_possible_score = sum(1.0 / (i + 1) for i in range(len(query)))\n",
        "    if max_possible_score > 0:\n",
        "        score = score / max_possible_score\n",
        "    \n",
        "    return score\n",
        "\n",
        "\n",
        "def find_k_nearest(query_history, k=K_NEIGHBORS):\n",
        "    \"\"\"\n",
        "    Find k nearest neighbor sequences based on similarity.\n",
        "    \n",
        "    Args:\n",
        "        query_history: List of encoded states (query sequence)\n",
        "        k: Number of neighbors to find\n",
        "    \n",
        "    Returns:\n",
        "        List of tuples: (sequence_index, similarity_score, next_location)\n",
        "        Sorted by similarity score (descending)\n",
        "    \"\"\"\n",
        "    if len(query_history) == 0:\n",
        "        return []\n",
        "    \n",
        "    similarities = []\n",
        "    \n",
        "    for idx, ref_seq in enumerate(reference_sequences):\n",
        "        # Calculate similarity\n",
        "        similarity = sequence_similarity(query_history, ref_seq)\n",
        "        \n",
        "        if similarity > 0:\n",
        "            # Find the next location after the matching prefix\n",
        "            lcp = longest_common_prefix(query_history, ref_seq)\n",
        "            if lcp < len(ref_seq):\n",
        "                next_location = ref_seq[lcp]\n",
        "                similarities.append((idx, similarity, next_location))\n",
        "    \n",
        "    # Sort by similarity (descending)\n",
        "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "    \n",
        "    # Return top-k\n",
        "    return similarities[:k]\n",
        "\n",
        "\n",
        "print(\"\\nKNN Trajectory Model built successfully!\")\n",
        "print(f\"Similarity functions:\")\n",
        "print(f\"  - longest_common_prefix(): Find matching prefix length\")\n",
        "print(f\"  - sequence_similarity(): Calculate weighted similarity score\")\n",
        "print(f\"  - find_k_nearest(): Find k most similar sequences\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 7 — Prediction Functions\n",
        "\n",
        "Implement prediction functions using KNN voting based on nearest neighbor sequences.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction functions defined successfully!\n",
            "\n",
            "Function summary:\n",
            "  - predict_next_location(query_history, k=5): Returns single most likely next state\n",
            "  - predict_top_k(query_history, k_neighbors=5, top_k=5): Returns top-K most likely next states\n"
          ]
        }
      ],
      "source": [
        "def predict_next_location(query_history, k=K_NEIGHBORS):\n",
        "    \"\"\"\n",
        "    Predict next location using KNN trajectory model.\n",
        "    \n",
        "    Args:\n",
        "        query_history: List of encoded states (history)\n",
        "        k: Number of nearest neighbors to consider\n",
        "    \n",
        "    Returns:\n",
        "        Predicted next state (encoded integer) or None\n",
        "    \"\"\"\n",
        "    if len(query_history) == 0:\n",
        "        return most_frequent_state if most_frequent_state is not None else None\n",
        "    \n",
        "    # Find k nearest neighbors\n",
        "    nearest = find_k_nearest(query_history, k=k)\n",
        "    \n",
        "    if not nearest:\n",
        "        # No similar sequences found, use most frequent state\n",
        "        return most_frequent_state if most_frequent_state is not None else None\n",
        "    \n",
        "    # Weighted voting: count votes weighted by similarity score\n",
        "    votes = defaultdict(float)\n",
        "    for _, similarity, next_location in nearest:\n",
        "        votes[next_location] += similarity\n",
        "    \n",
        "    if not votes:\n",
        "        return most_frequent_state if most_frequent_state is not None else None\n",
        "    \n",
        "    # Return location with highest weighted vote\n",
        "    predicted = max(votes.items(), key=lambda x: x[1])[0]\n",
        "    return int(predicted)\n",
        "\n",
        "\n",
        "def predict_top_k(query_history, k_neighbors=K_NEIGHBORS, top_k=5):\n",
        "    \"\"\"\n",
        "    Get top-K most likely next locations using KNN trajectory model.\n",
        "    \n",
        "    Args:\n",
        "        query_history: List of encoded states (history)\n",
        "        k_neighbors: Number of nearest neighbors to consider\n",
        "        top_k: Number of top predictions to return\n",
        "    \n",
        "    Returns:\n",
        "        List of top-K encoded states sorted by vote weight\n",
        "    \"\"\"\n",
        "    if len(query_history) == 0:\n",
        "        # Return top-K most frequent states\n",
        "        top_states = [state for state, _ in state_counts.most_common(top_k)]\n",
        "        return top_states[:top_k] if top_states else []\n",
        "    \n",
        "    # Find k nearest neighbors\n",
        "    nearest = find_k_nearest(query_history, k=k_neighbors)\n",
        "    \n",
        "    if not nearest:\n",
        "        # No similar sequences found, use most frequent states\n",
        "        top_states = [state for state, _ in state_counts.most_common(top_k)]\n",
        "        return top_states[:top_k] if top_states else []\n",
        "    \n",
        "    # Weighted voting: count votes weighted by similarity score\n",
        "    votes = defaultdict(float)\n",
        "    for _, similarity, next_location in nearest:\n",
        "        votes[next_location] += similarity\n",
        "    \n",
        "    if not votes:\n",
        "        top_states = [state for state, _ in state_counts.most_common(top_k)]\n",
        "        return top_states[:top_k] if top_states else []\n",
        "    \n",
        "    # Sort by vote weight (descending) and return top-K\n",
        "    sorted_locations = sorted(votes.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_k_locations = [int(loc) for loc, weight in sorted_locations[:top_k]]\n",
        "    \n",
        "    # If we have fewer than top_k, fill with most frequent states\n",
        "    if len(top_k_locations) < top_k:\n",
        "        existing = set(top_k_locations)\n",
        "        additional = [state for state, _ in state_counts.most_common(top_k) \n",
        "                     if state not in existing]\n",
        "        top_k_locations.extend(additional[:top_k - len(top_k_locations)])\n",
        "    \n",
        "    return top_k_locations[:top_k]\n",
        "\n",
        "\n",
        "print(\"Prediction functions defined successfully!\")\n",
        "print(\"\\nFunction summary:\")\n",
        "print(f\"  - predict_next_location(query_history, k={K_NEIGHBORS}): Returns single most likely next state\")\n",
        "print(f\"  - predict_top_k(query_history, k_neighbors={K_NEIGHBORS}, top_k=5): Returns top-K most likely next states\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model...\n",
            "Model saved to /home/root495/Inexture/Location Prediction Update/models/knn_trajectory_model.pkl\n",
            "Model contains:\n",
            "  - Reference trajectories: 119 sequences\n",
            "  - State frequencies: 286 states\n",
            "  - K neighbors: 5\n",
            "  - LabelEncoder and mappings\n"
          ]
        }
      ],
      "source": [
        "# Save model\n",
        "print(\"Saving model...\")\n",
        "model_data = {\n",
        "    'reference_sequences': reference_sequences,\n",
        "    'state_counts': dict(state_counts),\n",
        "    'most_frequent_state': most_frequent_state,\n",
        "    'k_neighbors': K_NEIGHBORS,\n",
        "    'label_encoder': le,\n",
        "    'encoded_to_placeid': encoded_to_placeid,\n",
        "    'n_states': n_states,\n",
        "    'similarity_metric': 'longest_common_prefix_weighted'\n",
        "}\n",
        "\n",
        "with open(MODEL_SAVE_PATH, 'wb') as f:\n",
        "    pickle.dump(model_data, f)\n",
        "\n",
        "print(f\"Model saved to {MODEL_SAVE_PATH}\")\n",
        "print(f\"Model contains:\")\n",
        "print(f\"  - Reference trajectories: {len(reference_sequences)} sequences\")\n",
        "print(f\"  - State frequencies: {len(state_counts)} states\")\n",
        "print(f\"  - K neighbors: {K_NEIGHBORS}\")\n",
        "print(f\"  - LabelEncoder and mappings\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 9 — Evaluation Setup\n",
        "\n",
        "Prepare test sequences and helper functions for evaluation metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test sequence length: 50 events\n",
            "Created 49 test cases\n",
            "Loaded coordinates for 2073 places\n",
            "Evaluation setup complete!\n"
          ]
        }
      ],
      "source": [
        "# Use first test sequence for evaluation (same as other notebooks for fair comparison)\n",
        "test_sequence = test_encoded[0]\n",
        "print(f\"Test sequence length: {len(test_sequence)} events\")\n",
        "\n",
        "# Create test cases: history -> next location\n",
        "test_cases = []\n",
        "for i in range(1, len(test_sequence)):\n",
        "    history = test_sequence[:i]\n",
        "    true_next = test_sequence[i]\n",
        "    test_cases.append((history, true_next))\n",
        "\n",
        "print(f\"Created {len(test_cases)} test cases\")\n",
        "\n",
        "# Load grid metadata and coordinates for MPD calculation\n",
        "with open(GRID_METADATA_FILE, 'r') as f:\n",
        "    grid_metadata = json.load(f)\n",
        "\n",
        "df_places = pd.read_csv(CLEANED_WITH_PLACES_FILE)\n",
        "place_coords = df_places.groupby('place_id')[['lat', 'lon']].first().to_dict('index')\n",
        "\n",
        "print(f\"Loaded coordinates for {len(place_coords)} places\")\n",
        "\n",
        "# Helper function to get coordinates from place_id\n",
        "def place_id_to_coords(place_id, place_coords, grid_metadata):\n",
        "    \"\"\"Get coordinates from place_id\"\"\"\n",
        "    if place_id is None:\n",
        "        return None, None\n",
        "    \n",
        "    # Try to find in place_coords first\n",
        "    if place_id in place_coords:\n",
        "        return place_coords[place_id]['lat'], place_coords[place_id]['lon']\n",
        "    \n",
        "    # Fallback: calculate from grid if place_id has format \"row_col\"\n",
        "    try:\n",
        "        if \"_\" in str(place_id):\n",
        "            row, col = map(int, str(place_id).split(\"_\"))\n",
        "            lat = grid_metadata['min_lat'] + row * grid_metadata['deg_lat']\n",
        "            lon = grid_metadata['min_lon'] + col * grid_metadata['deg_lon']\n",
        "            return lat, lon\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    return None, None\n",
        "\n",
        "print(\"Evaluation setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 10 — Metric 1: Accuracy\n",
        "\n",
        "Calculate accuracy: fraction of predictions that exactly match the true next location.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating Accuracy...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Making predictions: 100%|██████████| 49/49 [00:00<00:00, 1990.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Debug - First 5 predictions:\n",
            "  ✗ Pred: 219 (296_2075) | True: 213 (295_2076)\n",
            "  ✗ Pred: 220 (296_2076) | True: 214 (295_2077)\n",
            "  ✗ Pred: 220 (296_2076) | True: 213 (295_2076)\n",
            "  ✓ Pred: 220 (296_2076) | True: 220 (296_2076)\n",
            "  ✗ Pred: 220 (296_2076) | True: 219 (296_2075)\n",
            "\n",
            "============================================================\n",
            "METRIC 1: ACCURACY\n",
            "============================================================\n",
            "Correct predictions: 7\n",
            "Total predictions: 49\n",
            "Accuracy: 0.142857142857\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Calculate Accuracy\n",
        "print(\"Calculating Accuracy...\")\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "for history, true_next in tqdm(test_cases, desc=\"Making predictions\"):\n",
        "    pred = predict_next_location(history, k=K_NEIGHBORS)\n",
        "    if pred is not None:\n",
        "        predictions.append(pred)\n",
        "        true_labels.append(true_next)\n",
        "\n",
        "# Calculate accuracy\n",
        "if len(predictions) == 0:\n",
        "    print(\"ERROR: No predictions were made!\")\n",
        "    accuracy = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "else:\n",
        "    correct = sum(1 for p, t in zip(predictions, true_labels) if p == t)\n",
        "    total = len(predictions)\n",
        "    accuracy = correct / total if total > 0 else 0\n",
        "    \n",
        "    # Debug: Show first few predictions vs true\n",
        "    print(f\"\\nDebug - First 5 predictions:\")\n",
        "    for i in range(min(5, len(predictions))):\n",
        "        pred_place = encoded_to_placeid.get(predictions[i], \"Unknown\")\n",
        "        true_place = encoded_to_placeid.get(true_labels[i], \"Unknown\")\n",
        "        match = \"✓\" if predictions[i] == true_labels[i] else \"✗\"\n",
        "        print(f\"  {match} Pred: {predictions[i]} ({pred_place[:20]}) | True: {true_labels[i]} ({true_place[:20]})\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"METRIC 1: ACCURACY\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Correct predictions: {correct}\")\n",
        "print(f\"Total predictions: {total}\")\n",
        "print(f\"Accuracy: {accuracy:.12f}\")\n",
        "print(f\"{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 11 — Metric 2: Precision & Recall\n",
        "\n",
        "**Definition**: \n",
        "- **Precision**: How many predicted locations were actually correct, weighted by class frequency\n",
        "- **Recall**: Out of all true next locations, how many you successfully predicted, weighted by class frequency\n",
        "\n",
        "Measuring how trustworthy the model is with visited and predicted locations using weighted averages.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating Precision & Recall (Weighted)...\n",
            "\n",
            "============================================================\n",
            "METRIC 2: PRECISION & RECALL\n",
            "============================================================\n",
            "Precision: 0.020833333333\n",
            "Recall: 0.142857142857\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Calculate Precision & Recall (Weighted)\n",
        "print(\"Calculating Precision & Recall (Weighted)...\")\n",
        "\n",
        "if len(predictions) > 0:\n",
        "    precision_weighted = precision_score(true_labels, predictions, average='weighted', zero_division=0)\n",
        "    recall_weighted = recall_score(true_labels, predictions, average='weighted', zero_division=0)\n",
        "else:\n",
        "    precision_weighted = recall_weighted = 0\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"METRIC 2: PRECISION & RECALL\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Precision: {precision_weighted:.12f}\")\n",
        "print(f\"Recall: {recall_weighted:.12f}\")\n",
        "print(f\"{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 12 — Metric 3: Top-K Accuracy\n",
        "\n",
        "**Definition**: The true next location is considered correct if it appears in the top K predicted locations.\n",
        "\n",
        "Top-K Accuracy: If the true next position is included in the top-K predictions (K=1, 3, 5).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating Top-K Accuracy...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Top-1: 100%|██████████| 49/49 [00:00<00:00, 2472.46it/s]\n",
            "Top-3: 100%|██████████| 49/49 [00:00<00:00, 3033.03it/s]\n",
            "Top-5: 100%|██████████| 49/49 [00:00<00:00, 3281.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "METRIC 3: TOP-K ACCURACY\n",
            "============================================================\n",
            "Top-1 Accuracy: 0.142857142857\n",
            "Top-3 Accuracy: 0.367346938776\n",
            "Top-5 Accuracy: 0.448979591837\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Calculate Top-K Accuracy\n",
        "print(\"Calculating Top-K Accuracy...\")\n",
        "\n",
        "k_values = [1, 3, 5]\n",
        "top_k_results = {}\n",
        "\n",
        "for k in k_values:\n",
        "    correct_k = 0\n",
        "    total_k = 0\n",
        "    \n",
        "    for history, true_next in tqdm(test_cases, desc=f\"Top-{k}\"):\n",
        "        top_k_preds = predict_top_k(history, k_neighbors=K_NEIGHBORS, top_k=k)\n",
        "        if top_k_preds:\n",
        "            total_k += 1\n",
        "            if true_next in top_k_preds:\n",
        "                correct_k += 1\n",
        "    \n",
        "    top_k_accuracy = correct_k / total_k if total_k > 0 else 0\n",
        "    \n",
        "    top_k_results[k] = {\n",
        "        'correct': correct_k,\n",
        "        'total': total_k,\n",
        "        'accuracy': top_k_accuracy\n",
        "    }\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"METRIC 3: TOP-K ACCURACY\")\n",
        "print(f\"{'='*60}\")\n",
        "for k in k_values:\n",
        "    result = top_k_results[k]\n",
        "    print(f\"Top-{k} Accuracy: {result['accuracy']:.12f}\")\n",
        "print(f\"{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 13 — Metric 4: Mean Prediction Distance (MPD)\n",
        "\n",
        "**Definition**: Average Haversine distance (in meters) between actual next location and predicted next location.\n",
        "\n",
        "MPD Distance: Mean Prediction Distance — Mean actual distance visited from predicted location of next visit.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating Mean Prediction Distance (MPD)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Calculating distances: 100%|██████████| 49/49 [00:00<00:00, 104.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "METRIC 4: MEAN PREDICTION DISTANCE (MPD)\n",
            "============================================================\n",
            "MPD Distance: 17011.943966723749 meters\n",
            "Valid distance calculations: 49/49\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Calculate Mean Prediction Distance (MPD)\n",
        "print(\"Calculating Mean Prediction Distance (MPD)...\")\n",
        "\n",
        "distances = []\n",
        "failed_conversions = 0\n",
        "\n",
        "for history, true_next in tqdm(test_cases, desc=\"Calculating distances\"):\n",
        "    pred = predict_next_location(history, k=K_NEIGHBORS)\n",
        "    \n",
        "    if pred is not None:\n",
        "        # Convert encoded IDs back to place_ids\n",
        "        pred_place_id = encoded_to_placeid.get(pred)\n",
        "        true_place_id = encoded_to_placeid.get(true_next)\n",
        "        \n",
        "        if pred_place_id and true_place_id:\n",
        "            # Get coordinates\n",
        "            pred_lat, pred_lon = place_id_to_coords(pred_place_id, place_coords, grid_metadata)\n",
        "            true_lat, true_lon = place_id_to_coords(true_place_id, place_coords, grid_metadata)\n",
        "            \n",
        "            if pred_lat is not None and true_lat is not None:\n",
        "                # Calculate haversine distance\n",
        "                try:\n",
        "                    distance_m = haversine((pred_lat, pred_lon), (true_lat, true_lon)) * 1000\n",
        "                    # Filter out unrealistic distances (likely coordinate errors)\n",
        "                    if distance_m < 1000000:  # Less than 1000 km\n",
        "                        distances.append(distance_m)\n",
        "                    else:\n",
        "                        failed_conversions += 1\n",
        "                except:\n",
        "                    failed_conversions += 1\n",
        "            else:\n",
        "                failed_conversions += 1\n",
        "        else:\n",
        "            failed_conversions += 1\n",
        "    else:\n",
        "        failed_conversions += 1\n",
        "\n",
        "if failed_conversions > 0:\n",
        "    print(f\"Warning: {failed_conversions} distance calculations failed or were filtered\")\n",
        "\n",
        "mpd = np.mean(distances) if len(distances) > 0 else 0\n",
        "mpd_median = np.median(distances) if len(distances) > 0 else 0\n",
        "mpd_std = np.std(distances) if len(distances) > 0 else 0\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"METRIC 4: MEAN PREDICTION DISTANCE (MPD)\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"MPD Distance: {mpd:.12f} meters\")\n",
        "print(f\"Valid distance calculations: {len(distances)}/{len(test_cases)}\")\n",
        "print(f\"{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "EVALUATION RESULTS SUMMARY\n",
            "============================================================\n",
            "\n",
            "Number of users: 10\n",
            "Users: ['000', '001', '005', '006', '009', '011', '014', '016', '019', '025']\n",
            "Total original places: 1752364\n",
            "After duplicate removal: 4087\n",
            "Training sequences: 119\n",
            "Test sequences: 30\n",
            "\n",
            "1. ACCURACY\n",
            "   Accuracy: 0.142857142857\n",
            "\n",
            "2. PRECISION & RECALL\n",
            "   Precision: 0.020833333333\n",
            "   Recall: 0.142857142857\n",
            "\n",
            "3. TOP-K ACCURACY\n",
            "   Top-1 Accuracy: 0.142857142857\n",
            "   Top-3 Accuracy: 0.367346938776\n",
            "   Top-5 Accuracy: 0.448979591837\n",
            "\n",
            "4. MEAN PREDICTION DISTANCE (MPD)\n",
            "   MPD Distance: 17011.943966723749 meters\n",
            "\n",
            "============================================================\n",
            "\n",
            "Results saved to /home/root495/Inexture/Location Prediction Update/results/knn_trajectory_results.json\n",
            "\n",
            "Results Table:\n",
            "        Metric              Value\n",
            "      Accuracy     0.142857142857\n",
            "     Precision     0.020833333333\n",
            "        Recall     0.142857142857\n",
            "Top-1 Accuracy     0.142857142857\n",
            "Top-3 Accuracy     0.367346938776\n",
            "Top-5 Accuracy     0.448979591837\n",
            "  MPD Distance 17011.943966723749\n"
          ]
        }
      ],
      "source": [
        "# Compile all results\n",
        "results = {\n",
        "    'num_users': NUM_USERS,\n",
        "    'selected_users': selected_users,\n",
        "    'preprocessing': {\n",
        "        'total_original_places': total_original,\n",
        "        'total_after_duplicate_removal': total_processed,\n",
        "        'total_duplicates_removed': total_original - total_processed,\n",
        "        'sequence_length': SEQUENCE_LENGTH,\n",
        "        'total_sequences': len(all_sequences),\n",
        "        'training_sequences': len(train_sequences),\n",
        "        'test_sequences': len(test_sequences)\n",
        "    },\n",
        "    'model': {\n",
        "        'unique_states': n_states,\n",
        "        'model_type': 'knn_trajectory',\n",
        "        'k_neighbors': K_NEIGHBORS,\n",
        "        'num_reference_sequences': len(reference_sequences),\n",
        "        'similarity_metric': 'longest_common_prefix_weighted'\n",
        "    },\n",
        "    'accuracy': {\n",
        "        'value': accuracy,\n",
        "        'correct': correct,\n",
        "        'total': total\n",
        "    },\n",
        "    'precision_recall': {\n",
        "        'precision': float(precision_weighted),\n",
        "        'recall': float(recall_weighted)\n",
        "    },\n",
        "    'top_k_accuracy': {\n",
        "        f'top_{k}_accuracy': float(top_k_results[k]['accuracy']) for k in k_values\n",
        "    },\n",
        "    'mpd_distance': {\n",
        "        'mpd_distance_meters': float(mpd),\n",
        "        'valid_calculations': len(distances)\n",
        "    }\n",
        "}\n",
        "\n",
        "# Display summary\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"EVALUATION RESULTS SUMMARY\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"\\nNumber of users: {NUM_USERS}\")\n",
        "print(f\"Users: {selected_users}\")\n",
        "print(f\"Total original places: {total_original}\")\n",
        "print(f\"After duplicate removal: {total_processed}\")\n",
        "print(f\"Training sequences: {len(train_sequences)}\")\n",
        "print(f\"Test sequences: {len(test_sequences)}\")\n",
        "\n",
        "print(f\"\\n1. ACCURACY\")\n",
        "print(f\"   Accuracy: {accuracy:.12f}\")\n",
        "\n",
        "print(f\"\\n2. PRECISION & RECALL\")\n",
        "print(f\"   Precision: {precision_weighted:.12f}\")\n",
        "print(f\"   Recall: {recall_weighted:.12f}\")\n",
        "\n",
        "print(f\"\\n3. TOP-K ACCURACY\")\n",
        "for k in k_values:\n",
        "    acc = top_k_results[k]['accuracy']\n",
        "    print(f\"   Top-{k} Accuracy: {acc:.12f}\")\n",
        "\n",
        "print(f\"\\n4. MEAN PREDICTION DISTANCE (MPD)\")\n",
        "print(f\"   MPD Distance: {mpd:.12f} meters\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "\n",
        "# Save results\n",
        "with open(RESULTS_SAVE_PATH, 'w') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "print(f\"\\nResults saved to {RESULTS_SAVE_PATH}\")\n",
        "\n",
        "# Create results DataFrame\n",
        "results_df = pd.DataFrame({\n",
        "    'Metric': [\n",
        "        'Accuracy',\n",
        "        'Precision',\n",
        "        'Recall',\n",
        "        'Top-1 Accuracy',\n",
        "        'Top-3 Accuracy',\n",
        "        'Top-5 Accuracy',\n",
        "        'MPD Distance'\n",
        "    ],\n",
        "    'Value': [\n",
        "        f\"{accuracy:.12f}\",\n",
        "        f\"{precision_weighted:.12f}\",\n",
        "        f\"{recall_weighted:.12f}\",\n",
        "        f\"{top_k_results[1]['accuracy']:.12f}\",\n",
        "        f\"{top_k_results[3]['accuracy']:.12f}\",\n",
        "        f\"{top_k_results[5]['accuracy']:.12f}\",\n",
        "        f\"{mpd:.12f}\"\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(\"\\nResults Table:\")\n",
        "print(results_df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added new KNN Trajectory row to models_comparison.csv\n",
            "Updated /home/root495/Inexture/Location Prediction Update/results/models_comparison.csv\n",
            "\n",
            "Updated Models Comparison:\n",
            "         Model       Accuracy      Precision         Recall Top-1 Accuracy Top-3 Accuracy Top-5 Accuracy MPD Distance (meters)\n",
            "           HMM       0.653061       0.605081       0.653061       0.653061       0.897959       0.918367           4364.404451\n",
            "           GNN       0.504762       0.438886       0.504762       0.504762       0.691837       0.787075           3216.861429\n",
            "        Fusion       0.498639        0.44425       0.498639       0.498639       0.768027       0.819728           5196.347567\n",
            "  Markov Chain       0.693878       0.730539       0.693878       0.693878       0.918367       0.918367            3691.02685\n",
            "KNN Trajectory 0.142857142857 0.020833333333 0.142857142857 0.142857142857 0.367346938776 0.448979591837    17011.943966723749\n"
          ]
        }
      ],
      "source": [
        "# Update models_comparison.csv\n",
        "comparison_file = RESULTS_PATH + \"models_comparison.csv\"\n",
        "\n",
        "# Read existing comparison file\n",
        "try:\n",
        "    comparison_df = pd.read_csv(comparison_file)\n",
        "    \n",
        "    # Check if KNN Trajectory row already exists\n",
        "    if 'KNN Trajectory' in comparison_df['Model'].values:\n",
        "        # Update existing row\n",
        "        mask = comparison_df['Model'] == 'KNN Trajectory'\n",
        "        comparison_df.loc[mask, 'Accuracy'] = f\"{accuracy:.12f}\"\n",
        "        comparison_df.loc[mask, 'Precision'] = f\"{precision_weighted:.12f}\"\n",
        "        comparison_df.loc[mask, 'Recall'] = f\"{recall_weighted:.12f}\"\n",
        "        comparison_df.loc[mask, 'Top-1 Accuracy'] = f\"{top_k_results[1]['accuracy']:.12f}\"\n",
        "        comparison_df.loc[mask, 'Top-3 Accuracy'] = f\"{top_k_results[3]['accuracy']:.12f}\"\n",
        "        comparison_df.loc[mask, 'Top-5 Accuracy'] = f\"{top_k_results[5]['accuracy']:.12f}\"\n",
        "        comparison_df.loc[mask, 'MPD Distance (meters)'] = f\"{mpd:.12f}\"\n",
        "        print(\"Updated existing KNN Trajectory row in models_comparison.csv\")\n",
        "    else:\n",
        "        # Add new row\n",
        "        new_row = pd.DataFrame({\n",
        "            'Model': ['KNN Trajectory'],\n",
        "            'Accuracy': [f\"{accuracy:.12f}\"],\n",
        "            'Precision': [f\"{precision_weighted:.12f}\"],\n",
        "            'Recall': [f\"{recall_weighted:.12f}\"],\n",
        "            'Top-1 Accuracy': [f\"{top_k_results[1]['accuracy']:.12f}\"],\n",
        "            'Top-3 Accuracy': [f\"{top_k_results[3]['accuracy']:.12f}\"],\n",
        "            'Top-5 Accuracy': [f\"{top_k_results[5]['accuracy']:.12f}\"],\n",
        "            'MPD Distance (meters)': [f\"{mpd:.12f}\"]\n",
        "        })\n",
        "        comparison_df = pd.concat([comparison_df, new_row], ignore_index=True)\n",
        "        print(\"Added new KNN Trajectory row to models_comparison.csv\")\n",
        "    \n",
        "    # Save updated comparison file\n",
        "    comparison_df.to_csv(comparison_file, index=False)\n",
        "    print(f\"Updated {comparison_file}\")\n",
        "    \n",
        "    # Display updated comparison\n",
        "    print(\"\\nUpdated Models Comparison:\")\n",
        "    print(comparison_df.to_string(index=False))\n",
        "    \n",
        "except FileNotFoundError:\n",
        "    # Create new comparison file if it doesn't exist\n",
        "    comparison_df = pd.DataFrame({\n",
        "        'Model': ['KNN Trajectory'],\n",
        "        'Accuracy': [f\"{accuracy:.12f}\"],\n",
        "        'Precision': [f\"{precision_weighted:.12f}\"],\n",
        "        'Recall': [f\"{recall_weighted:.12f}\"],\n",
        "        'Top-1 Accuracy': [f\"{top_k_results[1]['accuracy']:.12f}\"],\n",
        "        'Top-3 Accuracy': [f\"{top_k_results[3]['accuracy']:.12f}\"],\n",
        "        'Top-5 Accuracy': [f\"{top_k_results[5]['accuracy']:.12f}\"],\n",
        "        'MPD Distance (meters)': [f\"{mpd:.12f}\"]\n",
        "    })\n",
        "    comparison_df.to_csv(comparison_file, index=False)\n",
        "    print(f\"Created new {comparison_file}\")\n",
        "except Exception as e:\n",
        "    print(f\"Warning: Could not update models_comparison.csv: {e}\")\n",
        "    print(\"Results have been saved to JSON file. Please update CSV manually if needed.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
