{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2nd Order Markov Chain Training on 10 Users' Trajectories\n",
        "\n",
        "This notebook:\n",
        "- Loads 10 users' trajectories (same as HMM/GNN/Fusion models)\n",
        "- Removes consecutive duplicates (AAABCDCCABB → ABCDCAB) for each user\n",
        "- Creates sequences of length 50 from all users\n",
        "- Trains a 2nd order Markov chain model (P(X_t | X_{t-1}, X_{t-2}))\n",
        "- Evaluates all 4 metrics: Accuracy, Precision & Recall, Top-K Accuracy, MPD\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1 — Imports & Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "from haversine import haversine\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from collections import defaultdict, Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds\n",
        "np.random.seed(42)\n",
        "\n",
        "# Paths\n",
        "BASE_PATH = \"/home/root495/Inexture/Location Prediction Update\"\n",
        "PROCESSED_PATH = BASE_PATH + \"/data/processed/\"\n",
        "SEQUENCES_FILE = PROCESSED_PATH + \"place_sequences.json\"\n",
        "GRID_METADATA_FILE = PROCESSED_PATH + \"grid_metadata.json\"\n",
        "CLEANED_WITH_PLACES_FILE = PROCESSED_PATH + \"cleaned_with_places.csv\"\n",
        "OUTPUT_PATH = BASE_PATH + \"/notebooks/\"\n",
        "MODELS_PATH = BASE_PATH + \"/models/\"\n",
        "RESULTS_PATH = BASE_PATH + \"/results/\"\n",
        "MODEL_SAVE_PATH = MODELS_PATH + \"markov_chain_2order_model.pkl\"\n",
        "RESULTS_SAVE_PATH = RESULTS_PATH + \"markov_chain_2order_results.json\"\n",
        "\n",
        "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "os.makedirs(MODELS_PATH, exist_ok=True)\n",
        "os.makedirs(RESULTS_PATH, exist_ok=True)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 2 — Load 10 Users' Trajectories\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading place sequences...\n",
            "Total users available: 54\n",
            "\n",
            "Selected 10 users: ['000', '001', '005', '006', '009', '011', '014', '016', '019', '025']\n",
            "  User 000: 173817 places\n",
            "  User 001: 108561 places\n",
            "  User 005: 108967 places\n",
            "  User 006: 31809 places\n",
            "  User 009: 84573 places\n",
            "  User 011: 90770 places\n",
            "  User 014: 388051 places\n",
            "  User 016: 89208 places\n",
            "  User 019: 47792 places\n",
            "  User 025: 628816 places\n",
            "\n",
            "Total places across all 10 users: 1752364\n"
          ]
        }
      ],
      "source": [
        "# Load place sequences\n",
        "print(\"Loading place sequences...\")\n",
        "with open(SEQUENCES_FILE, 'r') as f:\n",
        "    sequences_dict = json.load(f)\n",
        "\n",
        "print(f\"Total users available: {len(sequences_dict)}\")\n",
        "\n",
        "# Select first 10 users (same as HMM/GNN/Fusion models)\n",
        "user_ids = list(sequences_dict.keys())\n",
        "NUM_USERS = 10\n",
        "selected_users = user_ids[:NUM_USERS]\n",
        "\n",
        "print(f\"\\nSelected {NUM_USERS} users: {selected_users}\")\n",
        "\n",
        "# Load sequences for all selected users\n",
        "user_sequences = {}\n",
        "total_places = 0\n",
        "for user_id in selected_users:\n",
        "    seq = sequences_dict[user_id]\n",
        "    user_sequences[user_id] = seq\n",
        "    total_places += len(seq)\n",
        "    print(f\"  User {user_id}: {len(seq)} places\")\n",
        "\n",
        "print(f\"\\nTotal places across all {NUM_USERS} users: {total_places}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 3 — Preprocess: Remove Consecutive Duplicates\n",
        "\n",
        "Remove consecutive duplicate locations for each user. Example: AAABCDCCABB → ABCDCAB\n",
        "\n",
        "Only consecutive duplicates are removed. If a location appears again later (non-consecutive), it is kept.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing users...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Removing duplicates:   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  User 000: 173817 → 795 places (99.5% reduction)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Removing duplicates:  60%|██████    | 6/10 [00:00<00:00, 55.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  User 001: 108561 → 186 places (99.8% reduction)\n",
            "  User 005: 108967 → 283 places (99.7% reduction)\n",
            "  User 006: 31809 → 103 places (99.7% reduction)\n",
            "  User 009: 84573 → 17 places (100.0% reduction)\n",
            "  User 011: 90770 → 125 places (99.9% reduction)\n",
            "  User 014: 388051 → 766 places (99.8% reduction)\n",
            "  User 016: 89208 → 124 places (99.9% reduction)\n",
            "  User 019: 47792 → 120 places (99.7% reduction)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Removing duplicates: 100%|██████████| 10/10 [00:00<00:00, 28.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  User 025: 628816 → 1568 places (99.8% reduction)\n",
            "\n",
            "Summary:\n",
            "  Total original places: 1752364\n",
            "  Total after processing: 4087\n",
            "  Total duplicates removed: 1748277 (99.8%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def remove_consecutive_duplicates(sequence):\n",
        "    \"\"\"\n",
        "    Remove consecutive duplicates from sequence.\n",
        "    Example: [A, A, A, B, C, D, C, C, A, B, B] → [A, B, C, D, C, A, B]\n",
        "    \"\"\"\n",
        "    if len(sequence) == 0:\n",
        "        return sequence\n",
        "    \n",
        "    processed = [sequence[0]]  # Always keep first element\n",
        "    \n",
        "    for i in range(1, len(sequence)):\n",
        "        # Only add if different from previous (not consecutive duplicate)\n",
        "        if sequence[i] != sequence[i-1]:\n",
        "            processed.append(sequence[i])\n",
        "    \n",
        "    return processed\n",
        "\n",
        "# Apply consecutive duplicate removal to each user\n",
        "processed_sequences = {}\n",
        "total_original = 0\n",
        "total_processed = 0\n",
        "\n",
        "print(\"Processing users...\")\n",
        "for user_id in tqdm(selected_users, desc=\"Removing duplicates\"):\n",
        "    original_seq = user_sequences[user_id]\n",
        "    processed_seq = remove_consecutive_duplicates(original_seq)\n",
        "    processed_sequences[user_id] = processed_seq\n",
        "    \n",
        "    original_len = len(original_seq)\n",
        "    processed_len = len(processed_seq)\n",
        "    total_original += original_len\n",
        "    total_processed += processed_len\n",
        "    \n",
        "    reduction = original_len - processed_len\n",
        "    reduction_pct = (reduction / original_len * 100) if original_len > 0 else 0\n",
        "    print(f\"  User {user_id}: {original_len} → {processed_len} places ({reduction_pct:.1f}% reduction)\")\n",
        "\n",
        "print(f\"\\nSummary:\")\n",
        "print(f\"  Total original places: {total_original}\")\n",
        "print(f\"  Total after processing: {total_processed}\")\n",
        "print(f\"  Total duplicates removed: {total_original - total_processed} ({((total_original - total_processed)/total_original*100):.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 4 — Create Sequences of Length 50\n",
        "\n",
        "Split each user's processed sequence into fixed-length chunks of 50 events each.\n",
        "Combine sequences from all users for training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating sequences from all users...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing users: 100%|██████████| 10/10 [00:00<00:00, 13684.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  User 000: 30 sequences\n",
            "  User 001: 6 sequences\n",
            "  User 005: 10 sequences\n",
            "  User 006: 3 sequences\n",
            "  User 009: 0 sequences\n",
            "  User 011: 4 sequences\n",
            "  User 014: 29 sequences\n",
            "  User 016: 3 sequences\n",
            "  User 019: 3 sequences\n",
            "  User 025: 61 sequences\n",
            "\n",
            "Total sequences created: 149\n",
            "Total events in sequences: 7450\n",
            "\n",
            "Training sequences: 119\n",
            "Test sequences: 30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Create sequences of fixed length 50\n",
        "SEQUENCE_LENGTH = 50\n",
        "\n",
        "# Use sliding windows for more training data (overlap helps with learning)\n",
        "# Create overlapping sequences with step size of 25 (50% overlap)\n",
        "all_sequences = []\n",
        "step_size = 25  # Overlap of 50%\n",
        "\n",
        "print(\"Creating sequences from all users...\")\n",
        "for user_id in tqdm(selected_users, desc=\"Processing users\"):\n",
        "    processed_seq = processed_sequences[user_id]\n",
        "    user_sequences_list = []\n",
        "    \n",
        "    for i in range(0, len(processed_seq) - SEQUENCE_LENGTH + 1, step_size):\n",
        "        chunk = processed_seq[i:i+SEQUENCE_LENGTH]\n",
        "        if len(chunk) == SEQUENCE_LENGTH:  # Only full-length sequences\n",
        "            user_sequences_list.append(chunk)\n",
        "    \n",
        "    all_sequences.extend(user_sequences_list)\n",
        "    print(f\"  User {user_id}: {len(user_sequences_list)} sequences\")\n",
        "\n",
        "print(f\"\\nTotal sequences created: {len(all_sequences)}\")\n",
        "print(f\"Total events in sequences: {sum(len(s) for s in all_sequences)}\")\n",
        "\n",
        "# Split into train/test (80/20)\n",
        "split_idx = int(len(all_sequences) * 0.8)\n",
        "train_sequences = all_sequences[:split_idx]\n",
        "test_sequences = all_sequences[split_idx:]\n",
        "\n",
        "print(f\"\\nTraining sequences: {len(train_sequences)}\")\n",
        "print(f\"Test sequences: {len(test_sequences)}\")\n",
        "\n",
        "if len(test_sequences) == 0:\n",
        "    # If no test sequences, use last training sequence for testing\n",
        "    test_sequences = [train_sequences[-1]]\n",
        "    train_sequences = train_sequences[:-1]\n",
        "    print(f\"Adjusted: Training={len(train_sequences)}, Test=1 (using last training sequence)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 5 — Encode Sequences\n",
        "\n",
        "Encode place_ids to integers for Markov chain training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding sequences...\n",
            "Unique places across all users: 303\n",
            "Encoded 119 training sequences\n",
            "Encoded 30 test sequences\n",
            "Created mapping for 303 place IDs\n"
          ]
        }
      ],
      "source": [
        "# Encode sequences to integers\n",
        "print(\"Encoding sequences...\")\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Flatten all sequences for encoding\n",
        "all_places = [place for seq in train_sequences + test_sequences for place in seq]\n",
        "le.fit(all_places)\n",
        "\n",
        "n_states = len(le.classes_)\n",
        "print(f\"Unique places across all users: {n_states}\")\n",
        "\n",
        "# Encode training sequences\n",
        "train_encoded = []\n",
        "for seq in train_sequences:\n",
        "    encoded = le.transform(seq).tolist()\n",
        "    train_encoded.append(encoded)\n",
        "\n",
        "# Encode test sequences\n",
        "test_encoded = []\n",
        "for seq in test_sequences:\n",
        "    encoded = le.transform(seq).tolist()\n",
        "    test_encoded.append(encoded)\n",
        "\n",
        "print(f\"Encoded {len(train_encoded)} training sequences\")\n",
        "print(f\"Encoded {len(test_encoded)} test sequences\")\n",
        "\n",
        "# Create mapping from encoded ID to original place_id for coordinate lookup\n",
        "encoded_to_placeid = {}\n",
        "for place_id in le.classes_:\n",
        "    encoded_id = le.transform([place_id])[0]\n",
        "    encoded_to_placeid[int(encoded_id)] = place_id\n",
        "\n",
        "print(f\"Created mapping for {len(encoded_to_placeid)} place IDs\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 6 — Build 2nd Order Transition Matrix\n",
        "\n",
        "Build transition probability matrix: P(X_t | X_{t-1}, X_{t-2})\n",
        "\n",
        "Count all triplets (state_{t-2}, state_{t-1}, state_t) from training sequences and convert to probabilities.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building 2nd order transition matrix from training sequences...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Counting transitions: 100%|██████████| 119/119 [00:00<00:00, 6816.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Transition counts:\n",
            "  2nd order transitions: 5712\n",
            "  1st order transitions: 5831\n",
            "  Unique (prev2, prev1) pairs: 604\n",
            "  Unique prev1 states: 286\n",
            "\n",
            "Converting to probabilities...\n",
            "Built transition probability matrices:\n",
            "  2nd order: 604 (prev2, prev1) pairs\n",
            "  1st order: 286 prev states (for fallback)\n",
            "  Most frequent state: 220 (count: 1602)\n",
            "\n",
            "Validating probability distributions (checking first 3):\n",
            "  (219, 220): sum = 1.000000 (13 next states)\n",
            "  (220, 219): sum = 1.000000 (8 next states)\n",
            "  (219, 213): sum = 1.000000 (2 next states)\n",
            "\n",
            "2nd order transition matrix built successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Build 2nd order transition matrix\n",
        "# Structure: transitions[(prev2, prev1)][next_state] = count\n",
        "print(\"Building 2nd order transition matrix from training sequences...\")\n",
        "\n",
        "transitions_2order = defaultdict(lambda: defaultdict(int))  # 2nd order transitions\n",
        "transitions_1order = defaultdict(lambda: defaultdict(int))  # 1st order transitions (for fallback)\n",
        "state_counts = Counter()  # Overall state frequencies (for fallback)\n",
        "\n",
        "# Count all transitions from training sequences\n",
        "total_transitions_2order = 0\n",
        "total_transitions_1order = 0\n",
        "\n",
        "for seq in tqdm(train_encoded, desc=\"Counting transitions\"):\n",
        "    # Count 2nd order transitions: (state_{t-2}, state_{t-1}) -> state_t\n",
        "    for i in range(2, len(seq)):\n",
        "        prev2 = seq[i-2]\n",
        "        prev1 = seq[i-1]\n",
        "        next_state = seq[i]\n",
        "        transitions_2order[(prev2, prev1)][next_state] += 1\n",
        "        total_transitions_2order += 1\n",
        "    \n",
        "    # Count 1st order transitions: state_{t-1} -> state_t (for fallback)\n",
        "    for i in range(1, len(seq)):\n",
        "        prev1 = seq[i-1]\n",
        "        next_state = seq[i]\n",
        "        transitions_1order[prev1][next_state] += 1\n",
        "        total_transitions_1order += 1\n",
        "    \n",
        "    # Count state frequencies\n",
        "    for state in seq:\n",
        "        state_counts[state] += 1\n",
        "\n",
        "print(f\"\\nTransition counts:\")\n",
        "print(f\"  2nd order transitions: {total_transitions_2order}\")\n",
        "print(f\"  1st order transitions: {total_transitions_1order}\")\n",
        "print(f\"  Unique (prev2, prev1) pairs: {len(transitions_2order)}\")\n",
        "print(f\"  Unique prev1 states: {len(transitions_1order)}\")\n",
        "\n",
        "# Convert counts to probabilities for 2nd order\n",
        "print(\"\\nConverting to probabilities...\")\n",
        "transition_probs_2order = {}\n",
        "for (prev2, prev1), next_dict in transitions_2order.items():\n",
        "    total = sum(next_dict.values())\n",
        "    transition_probs_2order[(prev2, prev1)] = {\n",
        "        next_state: count / total for next_state, count in next_dict.items()\n",
        "    }\n",
        "\n",
        "# Convert counts to probabilities for 1st order (fallback)\n",
        "transition_probs_1order = {}\n",
        "for prev1, next_dict in transitions_1order.items():\n",
        "    total = sum(next_dict.values())\n",
        "    transition_probs_1order[prev1] = {\n",
        "        next_state: count / total for next_state, count in next_dict.items()\n",
        "    }\n",
        "\n",
        "# Get most frequent state (for final fallback)\n",
        "most_frequent_state = state_counts.most_common(1)[0][0] if state_counts else None\n",
        "\n",
        "print(f\"Built transition probability matrices:\")\n",
        "print(f\"  2nd order: {len(transition_probs_2order)} (prev2, prev1) pairs\")\n",
        "print(f\"  1st order: {len(transition_probs_1order)} prev states (for fallback)\")\n",
        "print(f\"  Most frequent state: {most_frequent_state} (count: {state_counts[most_frequent_state]})\")\n",
        "\n",
        "# Validate: Check that probabilities sum to 1.0 for a few examples\n",
        "print(\"\\nValidating probability distributions (checking first 3):\")\n",
        "for i, ((prev2, prev1), probs) in enumerate(list(transition_probs_2order.items())[:3]):\n",
        "    total_prob = sum(probs.values())\n",
        "    print(f\"  ({prev2}, {prev1}): sum = {total_prob:.6f} ({len(probs)} next states)\")\n",
        "\n",
        "print(\"\\n2nd order transition matrix built successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction functions defined successfully!\n",
            "\n",
            "Function summary:\n",
            "  - predict_next_location(history, use_patterns=True): Returns single most likely next state\n",
            "  - predict_top_k(history, k=5, use_patterns=True): Returns top-K most likely next states\n"
          ]
        }
      ],
      "source": [
        "def predict_next_location(history, use_patterns=True):\n",
        "    \"\"\"\n",
        "    Predict next location using 2nd order Markov chain.\n",
        "    \n",
        "    Args:\n",
        "        history: List of encoded states (integers)\n",
        "        use_patterns: Whether to use transition probabilities\n",
        "    \n",
        "    Returns:\n",
        "        Predicted next state (encoded integer) or None\n",
        "    \"\"\"\n",
        "    if len(history) == 0:\n",
        "        return most_frequent_state if most_frequent_state is not None else None\n",
        "    \n",
        "    if not use_patterns:\n",
        "        return most_frequent_state if most_frequent_state is not None else None\n",
        "    \n",
        "    # Strategy 1: Use 2nd order transition if history length >= 2\n",
        "    if len(history) >= 2:\n",
        "        prev2 = history[-2]\n",
        "        prev1 = history[-1]\n",
        "        key = (prev2, prev1)\n",
        "        \n",
        "        if key in transition_probs_2order:\n",
        "            next_probs = transition_probs_2order[key]\n",
        "            if next_probs:\n",
        "                # Return most likely next state\n",
        "                most_likely = max(next_probs.items(), key=lambda x: x[1])[0]\n",
        "                return int(most_likely)\n",
        "    \n",
        "    # Strategy 2: Fallback to 1st order if history length == 1\n",
        "    if len(history) == 1:\n",
        "        prev1 = history[-1]\n",
        "        if prev1 in transition_probs_1order:\n",
        "            next_probs = transition_probs_1order[prev1]\n",
        "            if next_probs:\n",
        "                most_likely = max(next_probs.items(), key=lambda x: x[1])[0]\n",
        "                return int(most_likely)\n",
        "    \n",
        "    # Strategy 3: Final fallback to most frequent state\n",
        "    return most_frequent_state if most_frequent_state is not None else None\n",
        "\n",
        "\n",
        "def predict_top_k(history, k=5, use_patterns=True):\n",
        "    \"\"\"\n",
        "    Get top-K most likely next locations using 2nd order Markov chain.\n",
        "    \n",
        "    Args:\n",
        "        history: List of encoded states (integers)\n",
        "        k: Number of top predictions to return\n",
        "        use_patterns: Whether to use transition probabilities\n",
        "    \n",
        "    Returns:\n",
        "        List of top-K encoded states\n",
        "    \"\"\"\n",
        "    if len(history) == 0:\n",
        "        # Return top-K most frequent states\n",
        "        top_states = [state for state, _ in state_counts.most_common(k)]\n",
        "        return top_states[:k] if top_states else []\n",
        "    \n",
        "    if not use_patterns:\n",
        "        top_states = [state for state, _ in state_counts.most_common(k)]\n",
        "        return top_states[:k] if top_states else []\n",
        "    \n",
        "    # Get probability distribution over all possible next states\n",
        "    next_state_probs = {}\n",
        "    \n",
        "    # Strategy 1: Use 2nd order transition if history length >= 2\n",
        "    if len(history) >= 2:\n",
        "        prev2 = history[-2]\n",
        "        prev1 = history[-1]\n",
        "        key = (prev2, prev1)\n",
        "        \n",
        "        if key in transition_probs_2order:\n",
        "            next_state_probs = transition_probs_2order[key].copy()\n",
        "    \n",
        "    # Strategy 2: If no 2nd order or incomplete, fallback to 1st order\n",
        "    if not next_state_probs and len(history) >= 1:\n",
        "        prev1 = history[-1]\n",
        "        if prev1 in transition_probs_1order:\n",
        "            next_state_probs = transition_probs_1order[prev1].copy()\n",
        "    \n",
        "    # Strategy 3: If still no probabilities, use state frequencies (normalized)\n",
        "    if not next_state_probs:\n",
        "        total_count = sum(state_counts.values())\n",
        "        if total_count > 0:\n",
        "            next_state_probs = {\n",
        "                state: count / total_count \n",
        "                for state, count in state_counts.items()\n",
        "            }\n",
        "    \n",
        "    # Return top-K states sorted by probability\n",
        "    if next_state_probs:\n",
        "        sorted_states = sorted(next_state_probs.items(), key=lambda x: x[1], reverse=True)\n",
        "        top_k_states = [int(state) for state, prob in sorted_states[:k]]\n",
        "        return top_k_states\n",
        "    \n",
        "    # Final fallback: most frequent states\n",
        "    top_states = [state for state, _ in state_counts.most_common(k)]\n",
        "    return top_states[:k] if top_states else []\n",
        "\n",
        "\n",
        "print(\"Prediction functions defined successfully!\")\n",
        "print(\"\\nFunction summary:\")\n",
        "print(\"  - predict_next_location(history, use_patterns=True): Returns single most likely next state\")\n",
        "print(\"  - predict_top_k(history, k=5, use_patterns=True): Returns top-K most likely next states\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model...\n",
            "Model saved to /home/root495/Inexture/Location Prediction Update/models/markov_chain_2order_model.pkl\n",
            "Model contains:\n",
            "  - 2nd order transition probabilities: 604 pairs\n",
            "  - 1st order transition probabilities: 286 states\n",
            "  - State frequencies: 286 states\n",
            "  - LabelEncoder and mappings\n"
          ]
        }
      ],
      "source": [
        "# Save model\n",
        "print(\"Saving model...\")\n",
        "model_data = {\n",
        "    'transition_probs_2order': dict(transition_probs_2order),\n",
        "    'transition_probs_1order': dict(transition_probs_1order),\n",
        "    'state_counts': dict(state_counts),\n",
        "    'most_frequent_state': most_frequent_state,\n",
        "    'label_encoder': le,\n",
        "    'encoded_to_placeid': encoded_to_placeid,\n",
        "    'n_states': n_states\n",
        "}\n",
        "\n",
        "with open(MODEL_SAVE_PATH, 'wb') as f:\n",
        "    pickle.dump(model_data, f)\n",
        "\n",
        "print(f\"Model saved to {MODEL_SAVE_PATH}\")\n",
        "print(f\"Model contains:\")\n",
        "print(f\"  - 2nd order transition probabilities: {len(transition_probs_2order)} pairs\")\n",
        "print(f\"  - 1st order transition probabilities: {len(transition_probs_1order)} states\")\n",
        "print(f\"  - State frequencies: {len(state_counts)} states\")\n",
        "print(f\"  - LabelEncoder and mappings\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 9 — Evaluation Setup\n",
        "\n",
        "Prepare test sequences and helper functions for evaluation metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test sequence length: 50 events\n",
            "Created 49 test cases\n",
            "Loaded coordinates for 2073 places\n",
            "Evaluation setup complete!\n"
          ]
        }
      ],
      "source": [
        "# Use first test sequence for evaluation (same as HMM notebook for fair comparison)\n",
        "test_sequence = test_encoded[0]\n",
        "print(f\"Test sequence length: {len(test_sequence)} events\")\n",
        "\n",
        "# Create test cases: history -> next location\n",
        "test_cases = []\n",
        "for i in range(1, len(test_sequence)):\n",
        "    history = test_sequence[:i]\n",
        "    true_next = test_sequence[i]\n",
        "    test_cases.append((history, true_next))\n",
        "\n",
        "print(f\"Created {len(test_cases)} test cases\")\n",
        "\n",
        "# Load grid metadata and coordinates for MPD calculation\n",
        "with open(GRID_METADATA_FILE, 'r') as f:\n",
        "    grid_metadata = json.load(f)\n",
        "\n",
        "df_places = pd.read_csv(CLEANED_WITH_PLACES_FILE)\n",
        "place_coords = df_places.groupby('place_id')[['lat', 'lon']].first().to_dict('index')\n",
        "\n",
        "print(f\"Loaded coordinates for {len(place_coords)} places\")\n",
        "\n",
        "# Helper function to get coordinates from place_id\n",
        "def place_id_to_coords(place_id, place_coords, grid_metadata):\n",
        "    \"\"\"Get coordinates from place_id\"\"\"\n",
        "    if place_id is None:\n",
        "        return None, None\n",
        "    \n",
        "    # Try to find in place_coords first\n",
        "    if place_id in place_coords:\n",
        "        return place_coords[place_id]['lat'], place_coords[place_id]['lon']\n",
        "    \n",
        "    # Fallback: calculate from grid if place_id has format \"row_col\"\n",
        "    try:\n",
        "        if \"_\" in str(place_id):\n",
        "            row, col = map(int, str(place_id).split(\"_\"))\n",
        "            lat = grid_metadata['min_lat'] + row * grid_metadata['deg_lat']\n",
        "            lon = grid_metadata['min_lon'] + col * grid_metadata['deg_lon']\n",
        "            return lat, lon\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    return None, None\n",
        "\n",
        "print(\"Evaluation setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 10 — Metric 1: Accuracy\n",
        "\n",
        "Calculate accuracy: fraction of predictions that exactly match the true next location.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating Accuracy...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Making predictions: 100%|██████████| 49/49 [00:00<00:00, 119907.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Debug - First 5 predictions:\n",
            "  ✗ Pred: 219 (296_2075) | True: 213 (295_2076)\n",
            "  ✗ Pred: 220 (296_2076) | True: 214 (295_2077)\n",
            "  ✓ Pred: 213 (295_2076) | True: 213 (295_2076)\n",
            "  ✗ Pred: 214 (295_2077) | True: 220 (296_2076)\n",
            "  ✓ Pred: 219 (296_2075) | True: 219 (296_2075)\n",
            "\n",
            "============================================================\n",
            "METRIC 1: ACCURACY\n",
            "============================================================\n",
            "Correct predictions: 34\n",
            "Total predictions: 49\n",
            "Accuracy: 0.693877551020\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Calculate Accuracy\n",
        "print(\"Calculating Accuracy...\")\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "for history, true_next in tqdm(test_cases, desc=\"Making predictions\"):\n",
        "    pred = predict_next_location(history, use_patterns=True)\n",
        "    if pred is not None:\n",
        "        predictions.append(pred)\n",
        "        true_labels.append(true_next)\n",
        "\n",
        "# Calculate accuracy\n",
        "if len(predictions) == 0:\n",
        "    print(\"ERROR: No predictions were made!\")\n",
        "    accuracy = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "else:\n",
        "    correct = sum(1 for p, t in zip(predictions, true_labels) if p == t)\n",
        "    total = len(predictions)\n",
        "    accuracy = correct / total if total > 0 else 0\n",
        "    \n",
        "    # Debug: Show first few predictions vs true\n",
        "    print(f\"\\nDebug - First 5 predictions:\")\n",
        "    for i in range(min(5, len(predictions))):\n",
        "        pred_place = encoded_to_placeid.get(predictions[i], \"Unknown\")\n",
        "        true_place = encoded_to_placeid.get(true_labels[i], \"Unknown\")\n",
        "        match = \"✓\" if predictions[i] == true_labels[i] else \"✗\"\n",
        "        print(f\"  {match} Pred: {predictions[i]} ({pred_place[:20]}) | True: {true_labels[i]} ({true_place[:20]})\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"METRIC 1: ACCURACY\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Correct predictions: {correct}\")\n",
        "print(f\"Total predictions: {total}\")\n",
        "print(f\"Accuracy: {accuracy:.12f}\")\n",
        "print(f\"{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 11 — Metric 2: Precision & Recall\n",
        "\n",
        "**Definition**: \n",
        "- **Precision**: How many predicted locations were actually correct, weighted by class frequency\n",
        "- **Recall**: Out of all true next locations, how many you successfully predicted, weighted by class frequency\n",
        "\n",
        "Measuring how trustworthy the model is with visited and predicted locations using weighted averages.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating Precision & Recall (Weighted)...\n",
            "\n",
            "============================================================\n",
            "METRIC 2: PRECISION & RECALL\n",
            "============================================================\n",
            "Precision: 0.730539301968\n",
            "Recall: 0.693877551020\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Calculate Precision & Recall (Weighted)\n",
        "print(\"Calculating Precision & Recall (Weighted)...\")\n",
        "\n",
        "if len(predictions) > 0:\n",
        "    precision_weighted = precision_score(true_labels, predictions, average='weighted', zero_division=0)\n",
        "    recall_weighted = recall_score(true_labels, predictions, average='weighted', zero_division=0)\n",
        "else:\n",
        "    precision_weighted = recall_weighted = 0\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"METRIC 2: PRECISION & RECALL\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Precision: {precision_weighted:.12f}\")\n",
        "print(f\"Recall: {recall_weighted:.12f}\")\n",
        "print(f\"{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 12 — Metric 3: Top-K Accuracy\n",
        "\n",
        "**Definition**: The true next location is considered correct if it appears in the top K predicted locations.\n",
        "\n",
        "Top-K Accuracy: If the true next position is included in the top-K predictions (K=1, 3, 5).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating Top-K Accuracy...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Top-1: 100%|██████████| 49/49 [00:00<00:00, 110080.82it/s]\n",
            "Top-3: 100%|██████████| 49/49 [00:00<00:00, 79535.95it/s]\n",
            "Top-5: 100%|██████████| 49/49 [00:00<00:00, 96443.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "METRIC 3: TOP-K ACCURACY\n",
            "============================================================\n",
            "Top-1 Accuracy: 0.693877551020\n",
            "Top-3 Accuracy: 0.918367346939\n",
            "Top-5 Accuracy: 0.918367346939\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Calculate Top-K Accuracy\n",
        "print(\"Calculating Top-K Accuracy...\")\n",
        "\n",
        "k_values = [1, 3, 5]\n",
        "top_k_results = {}\n",
        "\n",
        "for k in k_values:\n",
        "    correct_k = 0\n",
        "    total_k = 0\n",
        "    \n",
        "    for history, true_next in tqdm(test_cases, desc=f\"Top-{k}\"):\n",
        "        top_k_preds = predict_top_k(history, k=k, use_patterns=True)\n",
        "        if top_k_preds:\n",
        "            total_k += 1\n",
        "            if true_next in top_k_preds:\n",
        "                correct_k += 1\n",
        "    \n",
        "    top_k_accuracy = correct_k / total_k if total_k > 0 else 0\n",
        "    \n",
        "    top_k_results[k] = {\n",
        "        'correct': correct_k,\n",
        "        'total': total_k,\n",
        "        'accuracy': top_k_accuracy\n",
        "    }\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"METRIC 3: TOP-K ACCURACY\")\n",
        "print(f\"{'='*60}\")\n",
        "for k in k_values:\n",
        "    result = top_k_results[k]\n",
        "    print(f\"Top-{k} Accuracy: {result['accuracy']:.12f}\")\n",
        "print(f\"{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 13 — Metric 4: Mean Prediction Distance (MPD)\n",
        "\n",
        "**Definition**: Average Haversine distance (in meters) between actual next location and predicted next location.\n",
        "\n",
        "MPD Distance: Mean Prediction Distance — Mean actual distance visited from predicted location of next visit.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating Mean Prediction Distance (MPD)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Calculating distances: 100%|██████████| 49/49 [00:00<00:00, 54.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "METRIC 4: MEAN PREDICTION DISTANCE (MPD)\n",
            "============================================================\n",
            "MPD Distance: 3691.026849589245 meters\n",
            "Valid distance calculations: 49/49\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Calculate Mean Prediction Distance (MPD)\n",
        "print(\"Calculating Mean Prediction Distance (MPD)...\")\n",
        "\n",
        "distances = []\n",
        "failed_conversions = 0\n",
        "\n",
        "for history, true_next in tqdm(test_cases, desc=\"Calculating distances\"):\n",
        "    pred = predict_next_location(history, use_patterns=True)\n",
        "    \n",
        "    if pred is not None:\n",
        "        # Convert encoded IDs back to place_ids\n",
        "        pred_place_id = encoded_to_placeid.get(pred)\n",
        "        true_place_id = encoded_to_placeid.get(true_next)\n",
        "        \n",
        "        if pred_place_id and true_place_id:\n",
        "            # Get coordinates\n",
        "            pred_lat, pred_lon = place_id_to_coords(pred_place_id, place_coords, grid_metadata)\n",
        "            true_lat, true_lon = place_id_to_coords(true_place_id, place_coords, grid_metadata)\n",
        "            \n",
        "            if pred_lat is not None and true_lat is not None:\n",
        "                # Calculate haversine distance\n",
        "                try:\n",
        "                    distance_m = haversine((pred_lat, pred_lon), (true_lat, true_lon)) * 1000\n",
        "                    # Filter out unrealistic distances (likely coordinate errors)\n",
        "                    if distance_m < 1000000:  # Less than 1000 km\n",
        "                        distances.append(distance_m)\n",
        "                    else:\n",
        "                        failed_conversions += 1\n",
        "                except:\n",
        "                    failed_conversions += 1\n",
        "            else:\n",
        "                failed_conversions += 1\n",
        "        else:\n",
        "            failed_conversions += 1\n",
        "    else:\n",
        "        failed_conversions += 1\n",
        "\n",
        "if failed_conversions > 0:\n",
        "    print(f\"Warning: {failed_conversions} distance calculations failed or were filtered\")\n",
        "\n",
        "mpd = np.mean(distances) if len(distances) > 0 else 0\n",
        "mpd_median = np.median(distances) if len(distances) > 0 else 0\n",
        "mpd_std = np.std(distances) if len(distances) > 0 else 0\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"METRIC 4: MEAN PREDICTION DISTANCE (MPD)\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"MPD Distance: {mpd:.12f} meters\")\n",
        "print(f\"Valid distance calculations: {len(distances)}/{len(test_cases)}\")\n",
        "print(f\"{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "EVALUATION RESULTS SUMMARY\n",
            "============================================================\n",
            "\n",
            "Number of users: 10\n",
            "Users: ['000', '001', '005', '006', '009', '011', '014', '016', '019', '025']\n",
            "Total original places: 1752364\n",
            "After duplicate removal: 4087\n",
            "Training sequences: 119\n",
            "Test sequences: 30\n",
            "\n",
            "1. ACCURACY\n",
            "   Accuracy: 0.693877551020\n",
            "\n",
            "2. PRECISION & RECALL\n",
            "   Precision: 0.730539301968\n",
            "   Recall: 0.693877551020\n",
            "\n",
            "3. TOP-K ACCURACY\n",
            "   Top-1 Accuracy: 0.693877551020\n",
            "   Top-3 Accuracy: 0.918367346939\n",
            "   Top-5 Accuracy: 0.918367346939\n",
            "\n",
            "4. MEAN PREDICTION DISTANCE (MPD)\n",
            "   MPD Distance: 3691.026849589245 meters\n",
            "\n",
            "============================================================\n",
            "\n",
            "Results saved to /home/root495/Inexture/Location Prediction Update/results/markov_chain_2order_results.json\n",
            "\n",
            "Results Table:\n",
            "        Metric             Value\n",
            "      Accuracy    0.693877551020\n",
            "     Precision    0.730539301968\n",
            "        Recall    0.693877551020\n",
            "Top-1 Accuracy    0.693877551020\n",
            "Top-3 Accuracy    0.918367346939\n",
            "Top-5 Accuracy    0.918367346939\n",
            "  MPD Distance 3691.026849589245\n"
          ]
        }
      ],
      "source": [
        "# Compile all results\n",
        "results = {\n",
        "    'num_users': NUM_USERS,\n",
        "    'selected_users': selected_users,\n",
        "    'preprocessing': {\n",
        "        'total_original_places': total_original,\n",
        "        'total_after_duplicate_removal': total_processed,\n",
        "        'total_duplicates_removed': total_original - total_processed,\n",
        "        'sequence_length': SEQUENCE_LENGTH,\n",
        "        'total_sequences': len(all_sequences),\n",
        "        'training_sequences': len(train_sequences),\n",
        "        'test_sequences': len(test_sequences)\n",
        "    },\n",
        "    'model': {\n",
        "        'unique_states': n_states,\n",
        "        'order': 2,\n",
        "        'model_type': '2nd_order_markov_chain',\n",
        "        'num_2order_transitions': len(transition_probs_2order),\n",
        "        'num_1order_transitions': len(transition_probs_1order)\n",
        "    },\n",
        "    'accuracy': {\n",
        "        'value': accuracy,\n",
        "        'correct': correct,\n",
        "        'total': total\n",
        "    },\n",
        "    'precision_recall': {\n",
        "        'precision': float(precision_weighted),\n",
        "        'recall': float(recall_weighted)\n",
        "    },\n",
        "    'top_k_accuracy': {\n",
        "        f'top_{k}_accuracy': float(top_k_results[k]['accuracy']) for k in k_values\n",
        "    },\n",
        "    'mpd_distance': {\n",
        "        'mpd_distance_meters': float(mpd),\n",
        "        'valid_calculations': len(distances)\n",
        "    }\n",
        "}\n",
        "\n",
        "# Display summary\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"EVALUATION RESULTS SUMMARY\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"\\nNumber of users: {NUM_USERS}\")\n",
        "print(f\"Users: {selected_users}\")\n",
        "print(f\"Total original places: {total_original}\")\n",
        "print(f\"After duplicate removal: {total_processed}\")\n",
        "print(f\"Training sequences: {len(train_sequences)}\")\n",
        "print(f\"Test sequences: {len(test_sequences)}\")\n",
        "\n",
        "print(f\"\\n1. ACCURACY\")\n",
        "print(f\"   Accuracy: {accuracy:.12f}\")\n",
        "\n",
        "print(f\"\\n2. PRECISION & RECALL\")\n",
        "print(f\"   Precision: {precision_weighted:.12f}\")\n",
        "print(f\"   Recall: {recall_weighted:.12f}\")\n",
        "\n",
        "print(f\"\\n3. TOP-K ACCURACY\")\n",
        "for k in k_values:\n",
        "    acc = top_k_results[k]['accuracy']\n",
        "    print(f\"   Top-{k} Accuracy: {acc:.12f}\")\n",
        "\n",
        "print(f\"\\n4. MEAN PREDICTION DISTANCE (MPD)\")\n",
        "print(f\"   MPD Distance: {mpd:.12f} meters\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "\n",
        "# Save results\n",
        "with open(RESULTS_SAVE_PATH, 'w') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "print(f\"\\nResults saved to {RESULTS_SAVE_PATH}\")\n",
        "\n",
        "# Create results DataFrame\n",
        "results_df = pd.DataFrame({\n",
        "    'Metric': [\n",
        "        'Accuracy',\n",
        "        'Precision',\n",
        "        'Recall',\n",
        "        'Top-1 Accuracy',\n",
        "        'Top-3 Accuracy',\n",
        "        'Top-5 Accuracy',\n",
        "        'MPD Distance'\n",
        "    ],\n",
        "    'Value': [\n",
        "        f\"{accuracy:.12f}\",\n",
        "        f\"{precision_weighted:.12f}\",\n",
        "        f\"{recall_weighted:.12f}\",\n",
        "        f\"{top_k_results[1]['accuracy']:.12f}\",\n",
        "        f\"{top_k_results[3]['accuracy']:.12f}\",\n",
        "        f\"{top_k_results[5]['accuracy']:.12f}\",\n",
        "        f\"{mpd:.12f}\"\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(\"\\nResults Table:\")\n",
        "print(results_df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added new Markov Chain row to models_comparison.csv\n",
            "Updated /home/root495/Inexture/Location Prediction Update/results/models_comparison.csv\n",
            "\n",
            "Updated Models Comparison:\n",
            "       Model       Accuracy      Precision         Recall Top-1 Accuracy Top-3 Accuracy Top-5 Accuracy MPD Distance (meters)\n",
            "         HMM       0.653061       0.605081       0.653061       0.653061       0.897959       0.918367           4364.404451\n",
            "         GNN       0.504762       0.438886       0.504762       0.504762       0.691837       0.787075           3216.861429\n",
            "      Fusion       0.498639        0.44425       0.498639       0.498639       0.768027       0.819728           5196.347567\n",
            "Markov Chain 0.693877551020 0.730539301968 0.693877551020 0.693877551020 0.918367346939 0.918367346939     3691.026849589245\n"
          ]
        }
      ],
      "source": [
        "# Update models_comparison.csv\n",
        "comparison_file = RESULTS_PATH + \"models_comparison.csv\"\n",
        "\n",
        "# Read existing comparison file\n",
        "try:\n",
        "    comparison_df = pd.read_csv(comparison_file)\n",
        "    \n",
        "    # Check if Markov Chain row already exists\n",
        "    if 'Markov Chain' in comparison_df['Model'].values:\n",
        "        # Update existing row\n",
        "        mask = comparison_df['Model'] == 'Markov Chain'\n",
        "        comparison_df.loc[mask, 'Accuracy'] = f\"{accuracy:.12f}\"\n",
        "        comparison_df.loc[mask, 'Precision'] = f\"{precision_weighted:.12f}\"\n",
        "        comparison_df.loc[mask, 'Recall'] = f\"{recall_weighted:.12f}\"\n",
        "        comparison_df.loc[mask, 'Top-1 Accuracy'] = f\"{top_k_results[1]['accuracy']:.12f}\"\n",
        "        comparison_df.loc[mask, 'Top-3 Accuracy'] = f\"{top_k_results[3]['accuracy']:.12f}\"\n",
        "        comparison_df.loc[mask, 'Top-5 Accuracy'] = f\"{top_k_results[5]['accuracy']:.12f}\"\n",
        "        comparison_df.loc[mask, 'MPD Distance (meters)'] = f\"{mpd:.12f}\"\n",
        "        print(\"Updated existing Markov Chain row in models_comparison.csv\")\n",
        "    else:\n",
        "        # Add new row\n",
        "        new_row = pd.DataFrame({\n",
        "            'Model': ['Markov Chain'],\n",
        "            'Accuracy': [f\"{accuracy:.12f}\"],\n",
        "            'Precision': [f\"{precision_weighted:.12f}\"],\n",
        "            'Recall': [f\"{recall_weighted:.12f}\"],\n",
        "            'Top-1 Accuracy': [f\"{top_k_results[1]['accuracy']:.12f}\"],\n",
        "            'Top-3 Accuracy': [f\"{top_k_results[3]['accuracy']:.12f}\"],\n",
        "            'Top-5 Accuracy': [f\"{top_k_results[5]['accuracy']:.12f}\"],\n",
        "            'MPD Distance (meters)': [f\"{mpd:.12f}\"]\n",
        "        })\n",
        "        comparison_df = pd.concat([comparison_df, new_row], ignore_index=True)\n",
        "        print(\"Added new Markov Chain row to models_comparison.csv\")\n",
        "    \n",
        "    # Save updated comparison file\n",
        "    comparison_df.to_csv(comparison_file, index=False)\n",
        "    print(f\"Updated {comparison_file}\")\n",
        "    \n",
        "    # Display updated comparison\n",
        "    print(\"\\nUpdated Models Comparison:\")\n",
        "    print(comparison_df.to_string(index=False))\n",
        "    \n",
        "except FileNotFoundError:\n",
        "    # Create new comparison file if it doesn't exist\n",
        "    comparison_df = pd.DataFrame({\n",
        "        'Model': ['Markov Chain'],\n",
        "        'Accuracy': [f\"{accuracy:.12f}\"],\n",
        "        'Precision': [f\"{precision_weighted:.12f}\"],\n",
        "        'Recall': [f\"{recall_weighted:.12f}\"],\n",
        "        'Top-1 Accuracy': [f\"{top_k_results[1]['accuracy']:.12f}\"],\n",
        "        'Top-3 Accuracy': [f\"{top_k_results[3]['accuracy']:.12f}\"],\n",
        "        'Top-5 Accuracy': [f\"{top_k_results[5]['accuracy']:.12f}\"],\n",
        "        'MPD Distance (meters)': [f\"{mpd:.12f}\"]\n",
        "    })\n",
        "    comparison_df.to_csv(comparison_file, index=False)\n",
        "    print(f\"Created new {comparison_file}\")\n",
        "except Exception as e:\n",
        "    print(f\"Warning: Could not update models_comparison.csv: {e}\")\n",
        "    print(\"Results have been saved to JSON file. Please update CSV manually if needed.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
